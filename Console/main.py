import json
from pathlib import Path
import threading
import time

# ============================================================================
# 1. UTILIT√ÅRIOS DE REDE
# ============================================================================

def send_json(sock, data):
    """Envia um dicion√°rio Python como mensagem JSON via socket TCP.

    Protocolo de comunica√ß√£o:
        Cada mensagem √© serializada em JSON e finalizada com uma quebra de
        linha ('\n') para delimita√ß√£o no stream TCP. Isso permite ao receptor
        identificar o fim de cada mensagem de forma simples e eficiente.
        
    Args:
        sock: Socket TCP conectado (socket.socket).
        data: Dicion√°rio Python a ser enviado. Deve ser serializ√°vel em JSON.
        
    Raises:
        Exception: Capturada silenciosamente. Erros de pipe quebrado (EPIPE)
                   s√£o comuns durante o shutdown e n√£o necessitam tratamento.
                   
    Note:
        - Usa UTF-8 para compatibilidade universal.
        - sendall() garante envio completo da mensagem.
        - Failures silenciosos evitam poluir logs em situa√ß√µes normais de desconex√£o.
    """
    try:
        # Serializa dicion√°rio para string JSON e adiciona delimitador
        msg = json.dumps(data) + "\n"
        # Envia todos os bytes, bloqueando at√© completar
        sock.sendall(msg.encode('utf-8'))
    except Exception as e:
        # Erros de pipe quebrado s√£o comuns no shutdown coordenado
        # Silenciosamente ignorados para n√£o poluir logs
        pass

def recv_json(sock):
    """Recebe e desserializa mensagem JSON do socket TCP.

    Implementa um receptor baseado em buffer que acumula bytes at√© encontrar
    o delimitador de mensagem ('\n'). Esse padr√£o √© necess√°rio porque TCP √©
    orientado a stream e n√£o garante que recv() retorne mensagens completas.
    
    Args:
        sock: Socket TCP conectado (socket.socket).
        
    Returns:
        dict: Dicion√°rio Python desserializado da mensagem JSON, ou
        None: Se a conex√£o foi fechada ou ocorreu erro de parsing.
        
    Note:
        - Buffer acumula dados entre chamadas recv() parciais.
        - Tamanho do chunk (1024 bytes) balanceia lat√™ncia vs overhead de syscalls.
        - Descarta dados ap√≥s '\n' (rest) pois protocolo assume uma mensagem por linha.
        
    Behavior:
        - Chunk vazio: conex√£o fechada pelo peer ‚Üí retorna None.
        - Exce√ß√£o: erro de rede ou JSON inv√°lido ‚Üí retorna None.
    """
    buffer = ""  # Acumulador para dados parciais
    while True:
        try:
            # Recebe at√© 1KB de dados do socket
            chunk = sock.recv(1024).decode('utf-8')
            
            # Chunk vazio indica fechamento gracioso da conex√£o
            if not chunk:
                return None
            
            # Acumula no buffer para lidar com mensagens fragmentadas
            buffer += chunk
            
            # Procura delimitador de fim de mensagem
            if "\n" in buffer:
                # Extrai primeira mensagem completa
                msg, rest = buffer.split("\n", 1)
                # Desserializa JSON para dicion√°rio Python
                return json.loads(msg)
                
        except Exception:
            # Falha de rede, timeout, ou JSON malformado
            return None

# ============================================================================
# 2. CONFIGURA√á√ïES
# ============================================================================

BASE_DIR = Path(__file__).resolve().parent
TASKS_PATH = BASE_DIR / "tasks.json"

def get_port_for_server(server_id):
    """Gera porta TCP dinamicamente para qualquer ID de servidor.
    
    Args:
        server_id: Identificador num√©rico do servidor.
        
    Returns:
        int: N√∫mero da porta TCP (5001, 5002, 5003, ...).
        
    Note:
        Usa offset de 5000 para evitar portas privilegiadas (<1024)
        e conflitos com servi√ßos comuns (ex: 3000, 8080).
    """
    return 5000 + server_id

# ============================================================================
# 3. LOGGER
# ============================================================================

class RealtimeLogger:
    """Logger thread-safe para eventos em tempo real e agrega√ß√£o de m√©tricas.

    Esta classe centraliza o registro de eventos do sistema distribu√≠do,
    fornecendo timestamps formatados, categoriza√ß√£o de eventos e coleta
    de m√©tricas estat√≠sticas. Garante seguran√ßa em ambientes multithread
    usando locks expl√≠citos.
    
    Responsabilidades:
        - Emitir eventos formatados com timestamps relativos ao in√≠cio.
        - Acumular m√©tricas: requisi√ß√µes completas, CPU, preemp√ß√µes.
        - Garantir consist√™ncia de dados com acesso concorrente.
        - Fornecer visualiza√ß√£o humanizada de timestamps (mm:ss.mmm).
        
    Thread Safety:
        Todas as opera√ß√µes de escrita em `events` e `metrics` s√£o protegidas
        por `self.lock` para prevenir race conditions.
        
    Attributes:
        events (list): Hist√≥rico de mensagens de log formatadas.
        start_time (float): Timestamp Unix do in√≠cio da execu√ß√£o.
        metrics (dict): Agrega√ß√£o de m√©tricas num√©ricas.
        lock (threading.Lock): Mecanismo de sincroniza√ß√£o para acesso concorrente.
    """

    def __init__(self):
        """Inicializa logger com estruturas de dados vazias e timestamp de refer√™ncia."""
        # Hist√≥rico sequencial de todas as mensagens de log
        self.events = []
        
        # Marco temporal para c√°lculo de timestamps relativos
        self.start_time = time.time()
        
        # Contadores e acumuladores de m√©tricas
        self.metrics = {
            "requisicoes_completas": 0,      # Total de tarefas finalizadas
            "tempo_total_espera": 0,          # Acumulador para c√°lculo de m√©dia
            "max_tempo_espera": 0,            # M√°ximo tempo de resposta observado
            "cpu_valores": [],                # S√©rie temporal de amostras de CPU
            "preempcoes": 0                   # Total de interrup√ß√µes por quantum
        }
        
        # Lock para garantir atomicidade de opera√ß√µes em ambientes multithread
        self.lock = threading.Lock()

    def log(self, event_type, req_id=None, servidor_id=None, 
            prioridade=None, detalhes=""):
        """Registra evento categorizado com timestamp e contexto opcional.

        Formata mensagens de log de acordo com o tipo de evento, incluindo
        informa√ß√µes contextuais relevantes (IDs, prioridades, detalhes).
        Emite simultaneamente para console (stdout) e hist√≥rico interno.
        
        Args:
            event_type (str): Categoria do evento. Valores esperados:
                - "ATRIBUICAO": Tarefa enviada a um servidor.
                - "CONCLUSAO": Tarefa finalizada com sucesso.
                - "PREEMPCAO": Tarefa interrompida por quantum.
                - "INICIO": In√≠cio da execu√ß√£o do sistema.
                - "FIM": T√©rmino da execu√ß√£o.
                - Outros: Mensagem gen√©rica.
            req_id (int, optional): Identificador da requisi√ß√£o.
            servidor_id (int, optional): ID do servidor processador.
            prioridade (str, optional): N√≠vel de prioridade human-readable.
            detalhes (str, optional): Informa√ß√µes adicionais contextuais.
            
        Thread Safety:
            M√©todo √© thread-safe. Aquisi√ß√£o de lock antes de modificar `events`.
            
        Side Effects:
            - Imprime mensagem formatada no stdout.
            - Adiciona mensagem ao hist√≥rico interno (`self.events`).
        """
        # Calcula tempo decorrido desde o in√≠cio
        elapsed = time.time() - self.start_time
        # Converte para formato humanizado (mm:ss.mmm)
        timestamp = self._format_time(elapsed)

        if event_type == "ATRIBUICAO":
            msg = f"[{timestamp}] üì§ Requisi√ß√£o {req_id} ({prioridade}) " \
                  f"-> Enviada via SOCKET p/ Servidor {servidor_id} | {detalhes}"
        elif event_type == "CONCLUSAO":
            msg = f"[{timestamp}] ‚úÖ Servidor {servidor_id} " \
                  f"CONCLUIU Requisi√ß√£o {req_id}"
        elif event_type == "PREEMPCAO":
            msg = f"[{timestamp}] ‚è∏Ô∏è  Requisi√ß√£o {req_id} " \
                  f"PREEMPTADA (Recebida via Socket) - Resta: {detalhes}s"
        elif event_type == "INICIO":
            msg = f"[{timestamp}] ========== IN√çCIO DO SISTEMA DISTRIBU√çDO =========="
        elif event_type == "FIM":
            msg = f"[{timestamp}] ========== FIM DO PROCESSAMENTO =========="
        else:
            msg = f"[{timestamp}] {event_type}: {detalhes}"

        with self.lock:
            self.events.append(msg)
            print(msg)

    def _format_time(self, seconds):
        """Converte segundos decimais em timestamp humanizado.
        
        Args:
            seconds (float): Tempo em segundos (pode conter fra√ß√µes).
            
        Returns:
            str: Timestamp formatado como "MM:SS.mmm" onde:
                - MM: minutos (2 d√≠gitos, zero-padded)
                - SS: segundos (2 d√≠gitos, zero-padded)
                - mmm: milissegundos (3 d√≠gitos, zero-padded)
                
        Example:
            >>> _format_time(125.456)
            "02:05.456"
        """
        minutes = int(seconds) // 60          # Divis√£o inteira para minutos
        secs = int(seconds) % 60              # Resto para segundos
        ms = int((seconds % 1) * 1000)        # Fra√ß√£o para milissegundos
        return f"{minutes:02d}:{secs:02d}.{ms:03d}"

    def add_metric(self, metric_name, value):
        """Incrementa ou acrescenta valor a uma m√©trica existente.
        
        Suporta dois tipos de agrega√ß√£o:
            - Listas: append do novo valor (s√©ries temporais).
            - Num√©ricos: soma acumulativa (contadores).
            
        Args:
            metric_name (str): Nome da m√©trica em `self.metrics`.
            value: Valor a ser adicionado. Tipo deve ser compat√≠vel com
                   o tipo da m√©trica existente.
                   
        Thread Safety:
            Opera√ß√£o at√¥mica garantida por aquisi√ß√£o de lock.
            
        Note:
            Ignora silenciosamente m√©tricas inexistentes para evitar
            propaga√ß√£o de erros em paths de coleta.
        """
        with self.lock:
            # Verifica exist√™ncia da m√©trica no dicion√°rio
            if metric_name in self.metrics:
                # S√©ries temporais: acrescenta novo ponto
                if isinstance(self.metrics[metric_name], list):
                    self.metrics[metric_name].append(value)
                # Contadores: incrementa acumulador
                elif isinstance(self.metrics[metric_name], (int, float)):
                    self.metrics[metric_name] += value

# ============================================================================
# 4. ALGORITMO QUICK FIT (ADAPTADO PARA CARGA ATIVA)
# ============================================================================

class QuickFitAllocator:
    """Alocador Quick Fit adaptado para balanceamento din√¢mico de carga.

    Implementa uma varia√ß√£o do algoritmo Quick Fit cl√°ssico de aloca√ß√£o de
    mem√≥ria, adaptado para distribui√ß√£o de tarefas entre servidores com
    capacidades heterog√™neas e cargas vari√°veis em tempo real.
    
    Algoritmo de Sele√ß√£o (Least Connections com Desempates):
        1. Filtra servidores dispon√≠veis (carga < capacidade).
        2. Ordena por crit√©rios:
            a) Menor carga ativa (minimiza congestionamento).
            b) Maior capacidade (desempate, favorece servidores potentes).
            c) Menor ID (desempate determin√≠stico).
        3. Retorna o servidor ideal ou None se todos saturados.
        
    Diferen√ßas do Quick Fit Tradicional:
        - Original: aloca√ß√£o de blocos de mem√≥ria de tamanhos fixos.
        - Adaptado: distribui√ß√£o de tarefas considerando capacidade din√¢mica.
        
    Attributes:
        servidores (list): Lista de dicion√°rios com metadados dos servidores.
                          Cada item deve conter 'id' e 'capacidade'.
    """

    def __init__(self, servidores):
        """Inicializa alocador com configura√ß√£o de servidores.
        
        Args:
            servidores (list): Lista de servidores com schema:
                [{"id": int, "capacidade": int}, ...]
        """
        # Armazena refer√™ncia imut√°vel √† configura√ß√£o de servidores
        self.servidores = servidores

    def calcular_estado_servidores(self, task_queues, current_loads):
        """Gera snapshot consistente do estado de todos os servidores.

        Combina dados de configura√ß√£o est√°tica (capacidade) com m√©tricas
        din√¢micas (carga ativa) para determinar disponibilidade em tempo real.
        
        Args:
            task_queues (dict): Mapa {server_id: Queue} com filas de tarefas pendentes.
            current_loads (dict): Mapa {server_id: int} com contadores de tarefas
                                 em execu√ß√£o no momento (snapshot thread-safe).
                                 
        Returns:
            dict: Mapa {server_id: estado} onde cada estado cont√©m:
                - 'id' (int): Identificador do servidor.
                - 'capacidade' (int): M√°ximo de tarefas paralelas suportadas.
                - 'carga_atual' (int): Tarefas atualmente em execu√ß√£o.
                - 'pode_aceitar' (bool): True se carga < capacidade.
                
        Note:
            - Usa `current_loads` (contador controlado) ao inv√©s de `qsize()`
              (apenas tarefas enfileiradas) para refletir carga real.
            - Snapshot √© instant√¢neo mas pode desatualizar; lock externo
              garante consist√™ncia se necess√°rio.
        """
        estado = {}
        for server_id, queue_obj in task_queues.items():
            # Obt√©m capacidade te√≥rica da configura√ß√£o
            capacidade = self._get_capacidade(server_id)
            
            # Carga real: tarefas em execu√ß√£o (n√£o apenas na fila)
            # Fonte confi√°vel: contador mantido pelo Scheduler com locks
            carga_ativa = current_loads.get(server_id, 0)
            
            estado[server_id] = {
                'id': server_id,
                'capacidade': capacidade,
                'carga_atual': carga_ativa,
                # S√≥ aceita se carga ativa for menor que capacidade
                'pode_aceitar': carga_ativa < capacidade
            }
        return estado

    def _get_capacidade(self, server_id):
        """Consulta capacidade configurada de um servidor pelo ID.
        
        Args:
            server_id (int): Identificador do servidor.
            
        Returns:
            int: Capacidade (n√∫mero m√°ximo de tarefas paralelas) ou 1 se
                 servidor n√£o encontrado (fallback seguro).
                 
        Complexity:
            O(n) onde n = n√∫mero de servidores. Aceit√°vel para clusters pequenos.
            Para escala maior, considerar dicion√°rio indexado por ID.
        """
        for srv in self.servidores:
            if srv["id"] == server_id:
                return srv["capacidade"]
        # Fallback: assume capacidade unit√°ria se servidor n√£o encontrado
        return 1

    def encontrar_melhor_servidor(self, requisicao, estado_servidores):
        """Seleciona servidor ideal usando heur√≠stica Least Connections.

        Algoritmo de sele√ß√£o otimizado para minimizar congestionamento e
        aproveitar servidores de maior capacidade. Crit√©rios aplicados
        sequencialmente para desempate determin√≠stico.
        
        Args:
            requisicao (dict): Metadados da tarefa a ser alocada (n√£o usado
                              na vers√£o atual, reservado para extens√µes).
            estado_servidores (dict): Snapshot de estados retornado por
                                     calcular_estado_servidores().
                                     
        Returns:
            int: ID do servidor selecionado, ou
            None: Se todos os servidores est√£o saturados (carga ‚â• capacidade).
            
        Crit√©rios de Sele√ß√£o (em ordem de prioridade):
            1. **Menor carga atual**: Distribui uniformemente, evita hot spots.
            2. **Maior capacidade**: Em caso de empate, favorece servidores
               mais potentes (mais espa√ßo para crescimento).
            3. **Menor ID**: Desempate final determin√≠stico para reprodutibilidade.
            
        Complexity:
            O(n) onde n = n√∫mero de servidores dispon√≠veis.
            
        Note:
            Par√¢metro `requisicao` permite extens√µes futuras com sele√ß√£o
            baseada em caracter√≠sticas da tarefa (ex: tipo, prioridade).
        """
        # Fase 1: Filtra servidores que t√™m capacidade dispon√≠vel
        candidatos = [e for e in estado_servidores.values() if e['pode_aceitar']]
        
        # Se todos saturados, sinaliza impossibilidade de alocar
        if not candidatos:
            return None

        # Fase 2: Aplica crit√©rios de sele√ß√£o com tupla ordenada
        # Python compara tuplas lexicograficamente (elemento por elemento)
        melhor = min(
            candidatos,
            key=lambda est: (
                est['carga_atual'],      # 1¬∫: menor carga (menos congestionado)
                -est['capacidade'],      # 2¬∫: maior capacidade (nega para ordem decrescente)
                est['id']                # 3¬∫: menor ID (desempate determin√≠stico)
            )
        )
        return melhor['id']
