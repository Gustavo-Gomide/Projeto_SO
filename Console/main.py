import json
from pathlib import Path
import threading
import time
import socket

# ============================================================================
# 1. UTILIT√ÅRIOS DE REDE
# ============================================================================

def send_json(sock, data):
    """Envia um dicion√°rio Python como mensagem JSON via socket TCP.

    Protocolo de comunica√ß√£o:
        Cada mensagem √© serializada em JSON e finalizada com uma quebra de
        linha ('\n') para delimita√ß√£o no stream TCP. Isso permite ao receptor
        identificar o fim de cada mensagem de forma simples e eficiente.
        
    Args:
        sock: Socket TCP conectado (socket.socket).
        data: Dicion√°rio Python a ser enviado. Deve ser serializ√°vel em JSON.
        
    Raises:
        Exception: Capturada silenciosamente. Erros de pipe quebrado (EPIPE)
                   s√£o comuns durante o shutdown e n√£o necessitam tratamento.
                   
    Note:
        - Usa UTF-8 para compatibilidade universal.
        - sendall() garante envio completo da mensagem.
        - Failures silenciosos evitam poluir logs em situa√ß√µes normais de desconex√£o.
    """
    try:
        # Serializa dicion√°rio para string JSON e adiciona delimitador
        msg = json.dumps(data) + "\n"
        # Envia todos os bytes, bloqueando at√© completar
        sock.sendall(msg.encode('utf-8'))
    except Exception as e:
        # Erros de pipe quebrado s√£o comuns no shutdown coordenado
        # Silenciosamente ignorados para n√£o poluir logs
        pass

def recv_json(sock):
    """Recebe e desserializa mensagem JSON do socket TCP.

    Implementa um receptor baseado em buffer que acumula bytes at√© encontrar
    o delimitador de mensagem ('\n'). Esse padr√£o √© necess√°rio porque TCP √©
    orientado a stream e n√£o garante que recv() retorne mensagens completas.
    
    Args:
        sock: Socket TCP conectado (socket.socket).
        
    Returns:
        dict: Dicion√°rio Python desserializado da mensagem JSON, ou
        None: Se a conex√£o foi fechada ou ocorreu erro de parsing.
        
    Note:
        - Buffer acumula dados entre chamadas recv() parciais.
        - Tamanho do chunk (1024 bytes) balanceia lat√™ncia vs overhead de syscalls.
        - Descarta dados ap√≥s '\n' (rest) pois protocolo assume uma mensagem por linha.
        
    Behavior:
        - Chunk vazio: conex√£o fechada pelo peer ‚Üí retorna None.
        - Exce√ß√£o: erro de rede ou JSON inv√°lido ‚Üí retorna None.
    """
    buffer = ""  # Acumulador para dados parciais
    while True:
        try:
            # Recebe at√© 1KB de dados do socket
            chunk = sock.recv(1024).decode('utf-8')
            
            # Chunk vazio indica fechamento gracioso da conex√£o
            if not chunk:
                return None
            
            # Acumula no buffer para lidar com mensagens fragmentadas
            buffer += chunk
            
            # Procura delimitador de fim de mensagem
            if "\n" in buffer:
                # Extrai primeira mensagem completa
                msg, rest = buffer.split("\n", 1)
                # Desserializa JSON para dicion√°rio Python
                return json.loads(msg)
                
        except Exception:
            # Falha de rede, timeout, ou JSON malformado
            return None

# ============================================================================
# 2. CONFIGURA√á√ïES
# ============================================================================

BASE_DIR = Path(__file__).resolve().parent
TASKS_PATH = BASE_DIR / "tasks.json"

def get_port_for_server(server_id):
    """Gera porta TCP dinamicamente para qualquer ID de servidor.
    
    Args:
        server_id: Identificador num√©rico do servidor.
        
    Returns:
        int: N√∫mero da porta TCP (5001, 5002, 5003, ...).
        
    Note:
        Usa offset de 5000 para evitar portas privilegiadas (<1024)
        e conflitos com servi√ßos comuns (ex: 3000, 8080).
    """
    return 5000 + server_id

# ============================================================================
# 3. LOGGER
# ============================================================================

class RealtimeLogger:
    """Logger thread-safe para eventos em tempo real e agrega√ß√£o de m√©tricas.

    Esta classe centraliza o registro de eventos do sistema distribu√≠do,
    fornecendo timestamps formatados, categoriza√ß√£o de eventos e coleta
    de m√©tricas estat√≠sticas. Garante seguran√ßa em ambientes multithread
    usando locks expl√≠citos.
    
    Responsabilidades:
        - Emitir eventos formatados com timestamps relativos ao in√≠cio.
        - Acumular m√©tricas: requisi√ß√µes completas, CPU, preemp√ß√µes.
        - Garantir consist√™ncia de dados com acesso concorrente.
        - Fornecer visualiza√ß√£o humanizada de timestamps (mm:ss.mmm).
        
    Thread Safety:
        Todas as opera√ß√µes de escrita em `events` e `metrics` s√£o protegidas
        por `self.lock` para prevenir race conditions.
        
    Attributes:
        events (list): Hist√≥rico de mensagens de log formatadas.
        start_time (float): Timestamp Unix do in√≠cio da execu√ß√£o.
        metrics (dict): Agrega√ß√£o de m√©tricas num√©ricas.
        lock (threading.Lock): Mecanismo de sincroniza√ß√£o para acesso concorrente.
    """

    def __init__(self):
        """Inicializa logger com estruturas de dados vazias e timestamp de refer√™ncia."""
        # Hist√≥rico sequencial de todas as mensagens de log
        self.events = []
        
        # Marco temporal para c√°lculo de timestamps relativos
        self.start_time = time.time()
        
        # Contadores e acumuladores de m√©tricas
        self.metrics = {
            "requisicoes_completas": 0,      # Total de tarefas finalizadas
            "tempo_total_espera": 0,          # Acumulador para c√°lculo de m√©dia
            "max_tempo_espera": 0,            # M√°ximo tempo de resposta observado
            "cpu_valores": [],                # S√©rie temporal de amostras de CPU
            "preempcoes": 0                   # Total de interrup√ß√µes por quantum
        }
        
        # Lock para garantir atomicidade de opera√ß√µes em ambientes multithread
        self.lock = threading.Lock()

    def log(self, event_type, req_id=None, servidor_id=None, 
            prioridade=None, detalhes=""):
        """Registra evento categorizado com timestamp e contexto opcional.

        Formata mensagens de log de acordo com o tipo de evento, incluindo
        informa√ß√µes contextuais relevantes (IDs, prioridades, detalhes).
        Emite simultaneamente para console (stdout) e hist√≥rico interno.
        
        Args:
            event_type (str): Categoria do evento. Valores esperados:
                - "ATRIBUICAO": Tarefa enviada a um servidor.
                - "CONCLUSAO": Tarefa finalizada com sucesso.
                - "PREEMPCAO": Tarefa interrompida por quantum.
                - "INICIO": In√≠cio da execu√ß√£o do sistema.
                - "FIM": T√©rmino da execu√ß√£o.
                - Outros: Mensagem gen√©rica.
            req_id (int, optional): Identificador da requisi√ß√£o.
            servidor_id (int, optional): ID do servidor processador.
            prioridade (str, optional): N√≠vel de prioridade human-readable.
            detalhes (str, optional): Informa√ß√µes adicionais contextuais.
            
        Thread Safety:
            M√©todo √© thread-safe. Aquisi√ß√£o de lock antes de modificar `events`.
            
        Side Effects:
            - Imprime mensagem formatada no stdout.
            - Adiciona mensagem ao hist√≥rico interno (`self.events`).
        """
        # Calcula tempo decorrido desde o in√≠cio
        elapsed = time.time() - self.start_time
        # Converte para formato humanizado (mm:ss.mmm)
        timestamp = self._format_time(elapsed)

        if event_type == "ATRIBUICAO":
            msg = f"[{timestamp}] üì§ Requisi√ß√£o {req_id} ({prioridade}) " \
                  f"-> Enviada via SOCKET p/ Servidor {servidor_id} | {detalhes}"
        elif event_type == "CONCLUSAO":
            msg = f"[{timestamp}] ‚úÖ Servidor {servidor_id} " \
                  f"CONCLUIU Requisi√ß√£o {req_id}"
        elif event_type == "PREEMPCAO":
            msg = f"[{timestamp}] ‚è∏Ô∏è  Requisi√ß√£o {req_id} " \
                  f"PREEMPTADA (Recebida via Socket) - Resta: {detalhes}s"
        elif event_type == "INICIO":
            msg = f"[{timestamp}] ========== IN√çCIO DO SISTEMA DISTRIBU√çDO =========="
        elif event_type == "FIM":
            msg = f"[{timestamp}] ========== FIM DO PROCESSAMENTO =========="
        else:
            msg = f"[{timestamp}] {event_type}: {detalhes}"

        with self.lock:
            self.events.append(msg)
            print(msg)

    def _format_time(self, seconds):
        """Converte segundos decimais em timestamp humanizado.
        
        Args:
            seconds (float): Tempo em segundos (pode conter fra√ß√µes).
            
        Returns:
            str: Timestamp formatado como "MM:SS.mmm" onde:
                - MM: minutos (2 d√≠gitos, zero-padded)
                - SS: segundos (2 d√≠gitos, zero-padded)
                - mmm: milissegundos (3 d√≠gitos, zero-padded)
                
        Example:
            >>> _format_time(125.456)
            "02:05.456"
        """
        minutes = int(seconds) // 60          # Divis√£o inteira para minutos
        secs = int(seconds) % 60              # Resto para segundos
        ms = int((seconds % 1) * 1000)        # Fra√ß√£o para milissegundos
        return f"{minutes:02d}:{secs:02d}.{ms:03d}"

    def add_metric(self, metric_name, value):
        """Incrementa ou acrescenta valor a uma m√©trica existente.
        
        Suporta dois tipos de agrega√ß√£o:
            - Listas: append do novo valor (s√©ries temporais).
            - Num√©ricos: soma acumulativa (contadores).
            
        Args:
            metric_name (str): Nome da m√©trica em `self.metrics`.
            value: Valor a ser adicionado. Tipo deve ser compat√≠vel com
                   o tipo da m√©trica existente.
                   
        Thread Safety:
            Opera√ß√£o at√¥mica garantida por aquisi√ß√£o de lock.
            
        Note:
            Ignora silenciosamente m√©tricas inexistentes para evitar
            propaga√ß√£o de erros em paths de coleta.
        """
        with self.lock:
            # Verifica exist√™ncia da m√©trica no dicion√°rio
            if metric_name in self.metrics:
                # S√©ries temporais: acrescenta novo ponto
                if isinstance(self.metrics[metric_name], list):
                    self.metrics[metric_name].append(value)
                # Contadores: incrementa acumulador
                elif isinstance(self.metrics[metric_name], (int, float)):
                    self.metrics[metric_name] += value

# ============================================================================
# 4. ALGORITMO QUICK FIT (ADAPTADO PARA CARGA ATIVA)
# ============================================================================

class QuickFitAllocator:
    """Alocador Quick Fit adaptado para balanceamento din√¢mico de carga.

    Implementa uma varia√ß√£o do algoritmo Quick Fit cl√°ssico de aloca√ß√£o de
    mem√≥ria, adaptado para distribui√ß√£o de tarefas entre servidores com
    capacidades heterog√™neas e cargas vari√°veis em tempo real.
    
    Algoritmo de Sele√ß√£o (Least Connections com Desempates):
        1. Filtra servidores dispon√≠veis (carga < capacidade).
        2. Ordena por crit√©rios:
            a) Menor carga ativa (minimiza congestionamento).
            b) Maior capacidade (desempate, favorece servidores potentes).
            c) Menor ID (desempate determin√≠stico).
        3. Retorna o servidor ideal ou None se todos saturados.
        
    Diferen√ßas do Quick Fit Tradicional:
        - Original: aloca√ß√£o de blocos de mem√≥ria de tamanhos fixos.
        - Adaptado: distribui√ß√£o de tarefas considerando capacidade din√¢mica.
        
    Attributes:
        servidores (list): Lista de dicion√°rios com metadados dos servidores.
                          Cada item deve conter 'id' e 'capacidade'.
    """

    def __init__(self, servidores):
        """Inicializa alocador com configura√ß√£o de servidores.
        
        Args:
            servidores (list): Lista de servidores com schema:
                [{"id": int, "capacidade": int}, ...]
        """
        # Armazena refer√™ncia imut√°vel √† configura√ß√£o de servidores
        self.servidores = servidores

    def calcular_estado_servidores(self, task_queues, current_loads):
        """Gera snapshot consistente do estado de todos os servidores.

        Combina dados de configura√ß√£o est√°tica (capacidade) com m√©tricas
        din√¢micas (carga ativa) para determinar disponibilidade em tempo real.
        
        Args:
            task_queues (dict): Mapa {server_id: Queue} com filas de tarefas pendentes.
            current_loads (dict): Mapa {server_id: int} com contadores de tarefas
                                 em execu√ß√£o no momento (snapshot thread-safe).
                                 
        Returns:
            dict: Mapa {server_id: estado} onde cada estado cont√©m:
                - 'id' (int): Identificador do servidor.
                - 'capacidade' (int): M√°ximo de tarefas paralelas suportadas.
                - 'carga_atual' (int): Tarefas atualmente em execu√ß√£o.
                - 'pode_aceitar' (bool): True se carga < capacidade.
                
        Note:
            - Usa `current_loads` (contador controlado) ao inv√©s de `qsize()`
              (apenas tarefas enfileiradas) para refletir carga real.
            - Snapshot √© instant√¢neo mas pode desatualizar; lock externo
              garante consist√™ncia se necess√°rio.
        """
        estado = {}
        for server_id, queue_obj in task_queues.items():
            # Obt√©m capacidade te√≥rica da configura√ß√£o
            capacidade = self._get_capacidade(server_id)
            
            # Carga real: tarefas em execu√ß√£o (n√£o apenas na fila)
            # Fonte confi√°vel: contador mantido pelo Scheduler com locks
            carga_ativa = current_loads.get(server_id, 0)
            
            estado[server_id] = {
                'id': server_id,
                'capacidade': capacidade,
                'carga_atual': carga_ativa,
                # S√≥ aceita se carga ativa for menor que capacidade
                'pode_aceitar': carga_ativa < capacidade
            }
        return estado

    def _get_capacidade(self, server_id):
        """Consulta capacidade configurada de um servidor pelo ID.
        
        Args:
            server_id (int): Identificador do servidor.
            
        Returns:
            int: Capacidade (n√∫mero m√°ximo de tarefas paralelas) ou 1 se
                 servidor n√£o encontrado (fallback seguro).
                 
        Complexity:
            O(n) onde n = n√∫mero de servidores. Aceit√°vel para clusters pequenos.
            Para escala maior, considerar dicion√°rio indexado por ID.
        """
        for srv in self.servidores:
            if srv["id"] == server_id:
                return srv["capacidade"]
        # Fallback: assume capacidade unit√°ria se servidor n√£o encontrado
        return 1

    def encontrar_melhor_servidor(self, requisicao, estado_servidores):
        """Seleciona servidor ideal usando heur√≠stica Least Connections.

        Algoritmo de sele√ß√£o otimizado para minimizar congestionamento e
        aproveitar servidores de maior capacidade. Crit√©rios aplicados
        sequencialmente para desempate determin√≠stico.
        
        Args:
            requisicao (dict): Metadados da tarefa a ser alocada (n√£o usado
                              na vers√£o atual, reservado para extens√µes).
            estado_servidores (dict): Snapshot de estados retornado por
                                     calcular_estado_servidores().
                                     
        Returns:
            int: ID do servidor selecionado, ou
            None: Se todos os servidores est√£o saturados (carga ‚â• capacidade).
            
        Crit√©rios de Sele√ß√£o (em ordem de prioridade):
            1. **Menor carga atual**: Distribui uniformemente, evita hot spots.
            2. **Maior capacidade**: Em caso de empate, favorece servidores
               mais potentes (mais espa√ßo para crescimento).
            3. **Menor ID**: Desempate final determin√≠stico para reprodutibilidade.
            
        Complexity:
            O(n) onde n = n√∫mero de servidores dispon√≠veis.
            
        Note:
            Par√¢metro `requisicao` permite extens√µes futuras com sele√ß√£o
            baseada em caracter√≠sticas da tarefa (ex: tipo, prioridade).
        """
        # Fase 1: Filtra servidores que t√™m capacidade dispon√≠vel
        candidatos = [e for e in estado_servidores.values() if e['pode_aceitar']]
        
        # Se todos saturados, sinaliza impossibilidade de alocar
        if not candidatos:
            return None

        # Fase 2: Aplica crit√©rios de sele√ß√£o com tupla ordenada
        # Python compara tuplas lexicograficamente (elemento por elemento)
        melhor = min(
            candidatos,
            key=lambda est: (
                est['carga_atual'],      # 1¬∫: menor carga (menos congestionado)
                -est['capacidade'],      # 2¬∫: maior capacidade (nega para ordem decrescente)
                est['id']                # 3¬∫: menor ID (desempate determin√≠stico)
            )
        )
        return melhor['id']

# ============================================================================
# 5. WORKER (SERVIDOR SOCKET MULTITHREAD)
# ============================================================================

def fake_inference_core(requisicao, quantum):
    """Simula processamento de tarefa com consumo sint√©tico de CPU.

    Implementa loop de trabalho que respeita sem√¢ntica de quantum para
    escalonamento preemptivo. Combina sleep (I/O-bound) com c√°lculos
    (CPU-bound) para simular carga realista.
    
    Args:
        requisicao (dict): Metadados da tarefa contendo:
            - 'tempo_restante' (float): Tempo ainda n√£o processado.
            - 'tempo_exec' (float): Tempo total original (fallback).
        quantum (float): Limite de tempo para esta fatia de execu√ß√£o.
                        Se 0, executa at√© completar (modo FIFO/SJF).
                        
    Returns:
        tuple: (tempo_restante_novo, tempo_executado) onde:
            - tempo_restante_novo (float): Saldo ap√≥s esta execu√ß√£o.
            - tempo_executado (float): Dura√ß√£o efetiva desta fatia.
            
    Behavior:
        - Quantum 0: Executa tarefa completa (modo n√£o-preemptivo).
        - Quantum > 0: Limita execu√ß√£o a min(quantum, tempo_restante).
        - Trabalho sint√©tico: sleep + c√°lculos aritm√©ticos (simula mix I/O+CPU).
        
    Note:
        - Chunks de 0.1s balanceiam responsividade vs overhead de itera√ß√£o.
        - C√°lculo de quadrados gera carga CPU mensur√°vel para testes de desempenho.
    """
    # Obt√©m tempo pendente (prioriza 'tempo_restante' se dispon√≠vel)
    tempo_restante = requisicao.get("tempo_restante", requisicao.get("tempo_exec"))
    
    # Determina dura√ß√£o desta fatia de execu√ß√£o
    if quantum == 0:
        # Modo n√£o-preemptivo: executa at√© o fim
        tempo_execucao = tempo_restante
    else:
        # Modo preemptivo: respeita quantum ou termina se restar menos
        tempo_execucao = min(quantum, tempo_restante)

    # Marca in√≠cio para medi√ß√£o precisa de tempo decorrido
    start = time.time()
    elapsed = 0
    
    # Loop de trabalho: simula processamento em chunks
    while elapsed < tempo_execucao:
        # Calcula dura√ß√£o do pr√≥ximo chunk (m√°ximo 0.1s)
        chunk = min(0.1, tempo_execucao - elapsed)
        
        # Simula I/O-bound: espera passiva (libera CPU)
        time.sleep(chunk)
        
        # Simula CPU-bound: c√°lculo sint√©tico (consome ciclos)
        # Sum de quadrados gera carga mensur√°vel sem otimiza√ß√£o do interpretador
        _ = sum(i * i for i in range(1000))
        
        # Atualiza tempo decorrido (medi√ß√£o real, n√£o sleep nominal)
        elapsed = time.time() - start

    # Calcula saldo restante (garante n√£o-negativo por arredondamento)
    novo_tempo_restante = max(0, tempo_restante - tempo_execucao)
    return novo_tempo_restante, tempo_execucao

def process_task_thread(conn, lock, requisicao, quantum, server_id):
    """Worker thread que processa uma tarefa e envia resposta ao orquestrador.

    Cada tarefa recebida pelo servidor √© executada em uma thread independente,
    permitindo paralelismo real (m√∫ltiplas tarefas simult√¢neas por servidor).
    Ap√≥s processamento, envia resposta via socket com resultado (CONCLUSAO
    ou PREEMPCAO).
    
    Args:
        conn (socket.socket): Conex√£o TCP estabelecida com o orquestrador.
        lock (threading.Lock): Lock para serializar envios no socket compartilhado.
        requisicao (dict): Metadados da tarefa a processar.
        quantum (float): Limite de tempo por fatia (0 = sem limite).
        server_id (int): ID deste servidor (para logging/depura√ß√£o).
        
    Side Effects:
        - Modifica `requisicao['tempo_restante']` in-place.
        - Envia JSON via socket (CONCLUSAO ou PREEMPCAO).
        
    Thread Safety:
        - Lock protege send_json() contra intercala√ß√£o de mensagens.
        - `requisicao` √© c√≥pia independente (n√£o compartilhada entre threads).
        
    Protocol:
        Envia um dos dois tipos de resposta:
        - CONCLUSAO: Tarefa finalizada (tempo_restante ‚â§ 0.05s).
        - PREEMPCAO: Quantum esgotado, tarefa deve retornar √† fila.
    """
    # Extrai identificador para rastreabilidade
    req_id = requisicao.get("id")
    
    # Executa fatia de trabalho (respeita quantum)
    novo_restante, executado = fake_inference_core(requisicao, quantum)
    
    # Atualiza estado da requisi√ß√£o in-place (arredonda para evitar drift)
    requisicao['tempo_restante'] = round(novo_restante, 2)

    # Decide tipo de resposta baseado em crit√©rio de conclus√£o
    # Threshold de 0.05s tolera imprecis√µes de ponto flutuante
    if novo_restante <= 0.05:
        # Tarefa completa: envia resultado final
        resposta = {
            "tipo": "CONCLUSAO",
            "req_id": req_id,
            "servidor_id": server_id,
            "tempo_final": time.time(),       # Timestamp para m√©tricas
            "dados_originais": requisicao      # Estado final para auditoria
        }
    else:
        # Quantum esgotado: sinaliza preemp√ß√£o
        resposta = {
            "tipo": "PREEMPCAO",
            "req_id": req_id,
            "servidor_id": server_id,
            "tempo_restante": novo_restante,  # Saldo para pr√≥xima fatia
            "dados_originais": requisicao      # Estado parcial preservado
        }

    # Envia resposta com prote√ß√£o contra intercala√ß√£o
    # Lock necess√°rio pois m√∫ltiplas threads compartilham mesmo socket
    with lock:
        try:
            send_json(conn, resposta)
        except:
            # Falhas de envio (ex: conex√£o fechada) s√£o ignoradas
            # Servidor n√£o tem como reprocessar, responsabilidade do orquestrador
            pass

def run_socket_server(server_id, port, quantum):
    """Processo servidor independente que gerencia execu√ß√£o paralela de tarefas.

    Implementa servidor TCP multi-threaded que:
    1. Aceita conex√µes do orquestrador (permanentes durante sess√£o)
    2. Recebe tarefas via mensagens JSON delimitadas por '\n'
    3. Processa tarefas em threads paralelas (at√© capacidade do servidor)
    4. Envia respostas (CONCLUSAO/PREEMPCAO) de volta ao orquestrador
    5. Suporta shutdown gracioso via mensagem "STOP"
    
    Args:
        server_id (int): Identificador √∫nico deste servidor.
        port (int): Porta TCP para escutar (tipicamente 5000 + server_id).
        quantum (float): Limite de tempo por fatia de execu√ß√£o (0 = sem limite).
                        
    Lifecycle:
        1. Cria socket TCP em modo SO_REUSEADDR (permite restart r√°pido)
        2. Entra em loop accept() para aguardar conex√µes
        3. Para cada conex√£o: spawn thread por tarefa recebida
        4. Ao receber "STOP", encerra loops e fecha socket
        
    Concurrency:
        - Uma thread por tarefa ativa (paralelismo real limitado por GIL+I/O)
        - Lock por conex√£o protege envios no socket compartilhado
        - Threads s√£o daemon=True (encerram com processo pai)
        
    Protocol:
        - Input: JSON por linha (ex: {"id": 101, "tempo_exec": 5, ...})
        - Output: JSON por linha (ex: {"tipo": "CONCLUSAO", "req_id": 101, ...})
        - Control: String "STOP" encerra servidor
        
    Note:
        - Roda como processo separado (multiprocessing) para isolamento real.
        - SO_REUSEADDR evita erro "Address already in use" em restarts r√°pidos.
        - Backlog de 5 conex√µes pendentes suficiente para 1 cliente.
    """
    # Cria socket TCP IPv4
    server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    
    # Permite reusar porta imediatamente ap√≥s encerramento (evita TIME_WAIT)
    server_socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
    
    # Tenta ligar socket √† porta especificada
    try:
        server_socket.bind(('0.0.0.0', port))
        # Habilita modo listening com backlog=5 (at√© 5 conex√µes pendentes)
        server_socket.listen(5)
    except Exception as e:
        # Falha cr√≠tica: porta ocupada ou sem permiss√µes
        print(f"[Server {server_id}] Erro ao ligar na porta {port}: {e}")
        return

    # Loop principal: aguarda conex√µes indefinidamente
    while True:
        try:
            # Aceita pr√≥xima conex√£o (bloqueia at√© cliente conectar)
            conn, addr = server_socket.accept()
            
            # Lock exclusivo para esta conex√£o (protege send_json concorrente)
            socket_lock = threading.Lock()
            
            # Loop de recep√ß√£o: processa mensagens at√© STOP ou desconex√£o
            while True:
                # L√™ pr√≥xima mensagem JSON (bloqueia at√© receber linha completa)
                requisicao = recv_json(conn)
                
                # Verifica condi√ß√µes de t√©rmino
                if not requisicao:           # Conex√£o fechada ou erro de leitura
                    break
                if requisicao == "STOP":     # Comando de shutdown
                    break

                # Mensagem normal: trata como tarefa a processar
                # ARQUITETURA PARALELA: Uma thread por tarefa
                # Permite m√∫ltiplas tarefas simult√¢neas no mesmo servidor
                t = threading.Thread(
                    target=process_task_thread,
                    args=(conn, socket_lock, requisicao, quantum, server_id),
                    daemon=True  # Thread morre com processo pai
                )
                t.start()
            
            # Cleanup: fecha conex√£o ap√≥s loop interno
            conn.close()
            
            # Se recebeu STOP, encerra servidor completamente
            if requisicao == "STOP":
                break

        except Exception as e:
            # Erro de comunica√ß√£o: loga silenciosamente e aguarda pr√≥xima conex√£o
            # Comentado para evitar poluir stdout com erros esperados (ex: RST)
            # print(f"Erro na conex√£o do server {server_id}: {e}")
            pass
            
    # Cleanup final: fecha socket de escuta ao sair do loop
    server_socket.close()
