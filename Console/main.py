"""
=================================================================
BSB COMPUTE ‚Äî Sistema Distribu√≠do (Sockets TCP/IP)
=================================================================

Vis√£o geral
-----------
Este m√≥dulo implementa um sistema distribu√≠do simplificado com tr√™s
componentes principais:

- Servidores de execu√ß√£o: processos independentes (via `multiprocessing`)
    que aceitam tarefas por TCP, processam em threads para paralelismo real
    e retornam resultados ao orquestrador.
- Orquestrador (cliente): coordena o envio das tarefas, recebe as
    respostas, aplica pol√≠ticas de escalonamento (SJF, Round Robin, Prioridade)
    e faz o balanceamento com um alocador Quick Fit adaptado.
- Logger: gera logs em tempo real e coleta m√©tricas b√°sicas de execu√ß√£o.

Destaques de arquitetura
------------------------
- Comunica√ß√£o full-duplex por sockets com protocolo simples baseado em
    mensagens JSON terminadas por `\n`.
- Paralelismo real nos servidores: cada tarefa recebida √© processada em
    uma thread independente, permitindo m√∫ltiplas tarefas simult√¢neas.
- Controle de carga ativa: o orquestrador acompanha tarefas em execu√ß√£o
    por servidor e usa essa informa√ß√£o para decidir a aloca√ß√£o.
- Quick Fit (adaptado): seleciona o melhor servidor considerando menor
    carga ativa, maior capacidade como desempate e ID como crit√©rio final.

Estrat√©gias suportadas
----------------------
- SJF: menor tempo de execu√ß√£o primeiro (sem quantum).
- Round Robin: com quantum configur√°vel.
- Prioridade: ordena por prioridade (1=Alta, 2=M√©dia, 3=Baixa).
- FIFO: Round Robin com quantum zero (execu√ß√£o cont√≠nua).
"""

import json
import time
import threading
import multiprocessing
import psutil
import socket
from pathlib import Path
import queue

# ============================================================================
# 1. UTILIT√ÅRIOS DE REDE
# ============================================================================

def send_json(sock, data):
    """Envia um dicion√°rio Python como mensagem JSON via socket TCP.

    Protocolo de comunica√ß√£o:
        Cada mensagem √© serializada em JSON e finalizada com uma quebra de
        linha ('\n') para delimita√ß√£o no stream TCP. Isso permite ao receptor
        identificar o fim de cada mensagem de forma simples e eficiente.
        
    Args:
        sock: Socket TCP conectado (socket.socket).
        data: Dicion√°rio Python a ser enviado. Deve ser serializ√°vel em JSON.
        
    Raises:
        Exception: Capturada silenciosamente. Erros de pipe quebrado (EPIPE)
                   s√£o comuns durante o shutdown e n√£o necessitam tratamento.
                   
    Note:
        - Usa UTF-8 para compatibilidade universal.
        - sendall() garante envio completo da mensagem.
        - Failures silenciosos evitam poluir logs em situa√ß√µes normais de desconex√£o.
    """
    try:
        # Serializa dicion√°rio para string JSON e adiciona delimitador
        msg = json.dumps(data) + "\n"
        # Envia todos os bytes, bloqueando at√© completar
        sock.sendall(msg.encode('utf-8'))
    except Exception as e:
        # Erros de pipe quebrado s√£o comuns no shutdown coordenado
        # Silenciosamente ignorados para n√£o poluir logs
        pass

def recv_json(sock):
    """Recebe e desserializa mensagem JSON do socket TCP.

    Implementa um receptor baseado em buffer que acumula bytes at√© encontrar
    o delimitador de mensagem ('\n'). Esse padr√£o √© necess√°rio porque TCP √©
    orientado a stream e n√£o garante que recv() retorne mensagens completas.
    
    Args:
        sock: Socket TCP conectado (socket.socket).
        
    Returns:
        dict: Dicion√°rio Python desserializado da mensagem JSON, ou
        None: Se a conex√£o foi fechada ou ocorreu erro de parsing.
        
    Note:
        - Buffer acumula dados entre chamadas recv() parciais.
        - Tamanho do chunk (1024 bytes) balanceia lat√™ncia vs overhead de syscalls.
        - Descarta dados ap√≥s '\n' (rest) pois protocolo assume uma mensagem por linha.
        
    Behavior:
        - Chunk vazio: conex√£o fechada pelo peer ‚Üí retorna None.
        - Exce√ß√£o: erro de rede ou JSON inv√°lido ‚Üí retorna None.
    """
    buffer = ""  # Acumulador para dados parciais
    while True:
        try:
            # Recebe at√© 1KB de dados do socket
            chunk = sock.recv(1024).decode('utf-8')
            
            # Chunk vazio indica fechamento gracioso da conex√£o
            if not chunk:
                return None
            
            # Acumula no buffer para lidar com mensagens fragmentadas
            buffer += chunk
            
            # Procura delimitador de fim de mensagem
            if "\n" in buffer:
                # Extrai primeira mensagem completa
                msg, rest = buffer.split("\n", 1)
                # Desserializa JSON para dicion√°rio Python
                return json.loads(msg)
                
        except Exception:
            # Falha de rede, timeout, ou JSON malformado
            return None

# ============================================================================
# 2. CONFIGURA√á√ïES
# ============================================================================

BASE_DIR = Path(__file__).resolve().parent
TASKS_PATH = BASE_DIR / "tasks.json"

def get_port_for_server(server_id):
    """Gera porta TCP dinamicamente para qualquer ID de servidor.
    
    Args:
        server_id: Identificador num√©rico do servidor.
        
    Returns:
        int: N√∫mero da porta TCP (5001, 5002, 5003, ...).
        
    Note:
        Usa offset de 5000 para evitar portas privilegiadas (<1024)
        e conflitos com servi√ßos comuns (ex: 3000, 8080).
    """
    return 5000 + server_id

# ============================================================================
# 3. LOGGER
# ============================================================================

class RealtimeLogger:
    """Logger thread-safe para eventos em tempo real e agrega√ß√£o de m√©tricas.

    Esta classe centraliza o registro de eventos do sistema distribu√≠do,
    fornecendo timestamps formatados, categoriza√ß√£o de eventos e coleta
    de m√©tricas estat√≠sticas. Garante seguran√ßa em ambientes multithread
    usando locks expl√≠citos.
    
    Responsabilidades:
        - Emitir eventos formatados com timestamps relativos ao in√≠cio.
        - Acumular m√©tricas: requisi√ß√µes completas, CPU, preemp√ß√µes.
        - Garantir consist√™ncia de dados com acesso concorrente.
        - Fornecer visualiza√ß√£o humanizada de timestamps (mm:ss.mmm).
        
    Thread Safety:
        Todas as opera√ß√µes de escrita em `events` e `metrics` s√£o protegidas
        por `self.lock` para prevenir race conditions.
        
    Attributes:
        events (list): Hist√≥rico de mensagens de log formatadas.
        start_time (float): Timestamp Unix do in√≠cio da execu√ß√£o.
        metrics (dict): Agrega√ß√£o de m√©tricas num√©ricas.
        lock (threading.Lock): Mecanismo de sincroniza√ß√£o para acesso concorrente.
    """

    def __init__(self):
        """Inicializa logger com estruturas de dados vazias e timestamp de refer√™ncia."""
        # Hist√≥rico sequencial de todas as mensagens de log
        self.events = []
        
        # Marco temporal para c√°lculo de timestamps relativos
        self.start_time = time.time()
        
        # Contadores e acumuladores de m√©tricas
        self.metrics = {
            "requisicoes_completas": 0,      # Total de tarefas finalizadas
            "tempo_total_espera": 0,          # Acumulador para c√°lculo de m√©dia
            "max_tempo_espera": 0,            # M√°ximo tempo de resposta observado
            "cpu_valores": [],                # S√©rie temporal de amostras de CPU
            "preempcoes": 0                   # Total de interrup√ß√µes por quantum
        }
        
        # Lock para garantir atomicidade de opera√ß√µes em ambientes multithread
        self.lock = threading.Lock()

    def log(self, event_type, req_id=None, servidor_id=None, 
            prioridade=None, detalhes=""):
        """Registra evento categorizado com timestamp e contexto opcional.

        Formata mensagens de log de acordo com o tipo de evento, incluindo
        informa√ß√µes contextuais relevantes (IDs, prioridades, detalhes).
        Emite simultaneamente para console (stdout) e hist√≥rico interno.
        
        Args:
            event_type (str): Categoria do evento. Valores esperados:
                - "ATRIBUICAO": Tarefa enviada a um servidor.
                - "CONCLUSAO": Tarefa finalizada com sucesso.
                - "PREEMPCAO": Tarefa interrompida por quantum.
                - "INICIO": In√≠cio da execu√ß√£o do sistema.
                - "FIM": T√©rmino da execu√ß√£o.
                - Outros: Mensagem gen√©rica.
            req_id (int, optional): Identificador da requisi√ß√£o.
            servidor_id (int, optional): ID do servidor processador.
            prioridade (str, optional): N√≠vel de prioridade human-readable.
            detalhes (str, optional): Informa√ß√µes adicionais contextuais.
            
        Thread Safety:
            M√©todo √© thread-safe. Aquisi√ß√£o de lock antes de modificar `events`.
            
        Side Effects:
            - Imprime mensagem formatada no stdout.
            - Adiciona mensagem ao hist√≥rico interno (`self.events`).
        """
        # Calcula tempo decorrido desde o in√≠cio
        elapsed = time.time() - self.start_time
        # Converte para formato humanizado (mm:ss.mmm)
        timestamp = self._format_time(elapsed)

        if event_type == "ATRIBUICAO":
            msg = f"[{timestamp}] üì§ Requisi√ß√£o {req_id} ({prioridade}) " \
                  f"-> Enviada via SOCKET p/ Servidor {servidor_id} | {detalhes}"
        elif event_type == "CONCLUSAO":
            msg = f"[{timestamp}] ‚úÖ Servidor {servidor_id} " \
                  f"CONCLUIU Requisi√ß√£o {req_id}"
        elif event_type == "PREEMPCAO":
            msg = f"[{timestamp}] ‚è∏Ô∏è  Requisi√ß√£o {req_id} " \
                  f"PREEMPTADA (Recebida via Socket) - Resta: {detalhes}s"
        elif event_type == "INICIO":
            msg = f"[{timestamp}] ========== IN√çCIO DO SISTEMA DISTRIBU√çDO =========="
        elif event_type == "FIM":
            msg = f"[{timestamp}] ========== FIM DO PROCESSAMENTO =========="
        else:
            msg = f"[{timestamp}] {event_type}: {detalhes}"

        with self.lock:
            self.events.append(msg)
            print(msg)

    def _format_time(self, seconds):
        """Converte segundos decimais em timestamp humanizado.
        
        Args:
            seconds (float): Tempo em segundos (pode conter fra√ß√µes).
            
        Returns:
            str: Timestamp formatado como "MM:SS.mmm" onde:
                - MM: minutos (2 d√≠gitos, zero-padded)
                - SS: segundos (2 d√≠gitos, zero-padded)
                - mmm: milissegundos (3 d√≠gitos, zero-padded)
                
        Example:
            >>> _format_time(125.456)
            "02:05.456"
        """
        minutes = int(seconds) // 60          # Divis√£o inteira para minutos
        secs = int(seconds) % 60              # Resto para segundos
        ms = int((seconds % 1) * 1000)        # Fra√ß√£o para milissegundos
        return f"{minutes:02d}:{secs:02d}.{ms:03d}"

    def add_metric(self, metric_name, value):
        """Incrementa ou acrescenta valor a uma m√©trica existente.
        
        Suporta dois tipos de agrega√ß√£o:
            - Listas: append do novo valor (s√©ries temporais).
            - Num√©ricos: soma acumulativa (contadores).
            
        Args:
            metric_name (str): Nome da m√©trica em `self.metrics`.
            value: Valor a ser adicionado. Tipo deve ser compat√≠vel com
                   o tipo da m√©trica existente.
                   
        Thread Safety:
            Opera√ß√£o at√¥mica garantida por aquisi√ß√£o de lock.
            
        Note:
            Ignora silenciosamente m√©tricas inexistentes para evitar
            propaga√ß√£o de erros em paths de coleta.
        """
        with self.lock:
            # Verifica exist√™ncia da m√©trica no dicion√°rio
            if metric_name in self.metrics:
                # S√©ries temporais: acrescenta novo ponto
                if isinstance(self.metrics[metric_name], list):
                    self.metrics[metric_name].append(value)
                # Contadores: incrementa acumulador
                elif isinstance(self.metrics[metric_name], (int, float)):
                    self.metrics[metric_name] += value

# ============================================================================
# 4. ALGORITMO QUICK FIT (ADAPTADO PARA CARGA ATIVA)
# ============================================================================

class QuickFitAllocator:
    """Alocador Quick Fit adaptado para balanceamento din√¢mico de carga.

    Implementa uma varia√ß√£o do algoritmo Quick Fit cl√°ssico de aloca√ß√£o de
    mem√≥ria, adaptado para distribui√ß√£o de tarefas entre servidores com
    capacidades heterog√™neas e cargas vari√°veis em tempo real.
    
    Algoritmo de Sele√ß√£o (Least Connections com Desempates):
        1. Filtra servidores dispon√≠veis (carga < capacidade).
        2. Ordena por crit√©rios:
            a) Menor carga ativa (minimiza congestionamento).
            b) Maior capacidade (desempate, favorece servidores potentes).
            c) Menor ID (desempate determin√≠stico).
        3. Retorna o servidor ideal ou None se todos saturados.
        
    Diferen√ßas do Quick Fit Tradicional:
        - Original: aloca√ß√£o de blocos de mem√≥ria de tamanhos fixos.
        - Adaptado: distribui√ß√£o de tarefas considerando capacidade din√¢mica.
        
    Attributes:
        servidores (list): Lista de dicion√°rios com metadados dos servidores.
                          Cada item deve conter 'id' e 'capacidade'.
    """

    def __init__(self, servidores):
        """Inicializa alocador com configura√ß√£o de servidores.
        
        Args:
            servidores (list): Lista de servidores com schema:
                [{"id": int, "capacidade": int}, ...]
        """
        # Armazena refer√™ncia imut√°vel √† configura√ß√£o de servidores
        self.servidores = servidores

    def calcular_estado_servidores(self, task_queues, current_loads):
        """Gera snapshot consistente do estado de todos os servidores.

        Combina dados de configura√ß√£o est√°tica (capacidade) com m√©tricas
        din√¢micas (carga ativa) para determinar disponibilidade em tempo real.
        
        Args:
            task_queues (dict): Mapa {server_id: Queue} com filas de tarefas pendentes.
            current_loads (dict): Mapa {server_id: int} com contadores de tarefas
                                 em execu√ß√£o no momento (snapshot thread-safe).
                                 
        Returns:
            dict: Mapa {server_id: estado} onde cada estado cont√©m:
                - 'id' (int): Identificador do servidor.
                - 'capacidade' (int): M√°ximo de tarefas paralelas suportadas.
                - 'carga_atual' (int): Tarefas atualmente em execu√ß√£o.
                - 'pode_aceitar' (bool): True se carga < capacidade.
                
        Note:
            - Usa `current_loads` (contador controlado) ao inv√©s de `qsize()`
              (apenas tarefas enfileiradas) para refletir carga real.
            - Snapshot √© instant√¢neo mas pode desatualizar; lock externo
              garante consist√™ncia se necess√°rio.
        """
        estado = {}
        for server_id, queue_obj in task_queues.items():
            # Obt√©m capacidade te√≥rica da configura√ß√£o
            capacidade = self._get_capacidade(server_id)
            
            # Carga real: tarefas em execu√ß√£o (n√£o apenas na fila)
            # Fonte confi√°vel: contador mantido pelo Scheduler com locks
            carga_ativa = current_loads.get(server_id, 0)
            
            estado[server_id] = {
                'id': server_id,
                'capacidade': capacidade,
                'carga_atual': carga_ativa,
                # S√≥ aceita se carga ativa for menor que capacidade
                'pode_aceitar': carga_ativa < capacidade
            }
        return estado

    def _get_capacidade(self, server_id):
        """Consulta capacidade configurada de um servidor pelo ID.
        
        Args:
            server_id (int): Identificador do servidor.
            
        Returns:
            int: Capacidade (n√∫mero m√°ximo de tarefas paralelas) ou 1 se
                 servidor n√£o encontrado (fallback seguro).
                 
        Complexity:
            O(n) onde n = n√∫mero de servidores. Aceit√°vel para clusters pequenos.
            Para escala maior, considerar dicion√°rio indexado por ID.
        """
        for srv in self.servidores:
            if srv["id"] == server_id:
                return srv["capacidade"]
        # Fallback: assume capacidade unit√°ria se servidor n√£o encontrado
        return 1

    def encontrar_melhor_servidor(self, requisicao, estado_servidores):
        """Seleciona servidor ideal usando heur√≠stica Least Connections.

        Algoritmo de sele√ß√£o otimizado para minimizar congestionamento e
        aproveitar servidores de maior capacidade. Crit√©rios aplicados
        sequencialmente para desempate determin√≠stico.
        
        Args:
            requisicao (dict): Metadados da tarefa a ser alocada (n√£o usado
                              na vers√£o atual, reservado para extens√µes).
            estado_servidores (dict): Snapshot de estados retornado por
                                     calcular_estado_servidores().
                                     
        Returns:
            int: ID do servidor selecionado, ou
            None: Se todos os servidores est√£o saturados (carga ‚â• capacidade).
            
        Crit√©rios de Sele√ß√£o (em ordem de prioridade):
            1. **Menor carga atual**: Distribui uniformemente, evita hot spots.
            2. **Maior capacidade**: Em caso de empate, favorece servidores
               mais potentes (mais espa√ßo para crescimento).
            3. **Menor ID**: Desempate final determin√≠stico para reprodutibilidade.
            
        Complexity:
            O(n) onde n = n√∫mero de servidores dispon√≠veis.
            
        Note:
            Par√¢metro `requisicao` permite extens√µes futuras com sele√ß√£o
            baseada em caracter√≠sticas da tarefa (ex: tipo, prioridade).
        """
        # Fase 1: Filtra servidores que t√™m capacidade dispon√≠vel
        candidatos = [e for e in estado_servidores.values() if e['pode_aceitar']]
        
        # Se todos saturados, sinaliza impossibilidade de alocar
        if not candidatos:
            return None

        # Fase 2: Aplica crit√©rios de sele√ß√£o com tupla ordenada
        # Python compara tuplas lexicograficamente (elemento por elemento)
        melhor = min(
            candidatos,
            key=lambda est: (
                est['carga_atual'],      # 1¬∫: menor carga (menos congestionado)
                -est['capacidade'],      # 2¬∫: maior capacidade (nega para ordem decrescente)
                est['id']                # 3¬∫: menor ID (desempate determin√≠stico)
            )
        )
        return melhor['id']

# ============================================================================
# 5. WORKER (SERVIDOR SOCKET MULTITHREAD)
# ============================================================================

def fake_inference_core(requisicao, quantum):
    """Simula processamento de tarefa com consumo sint√©tico de CPU.

    Implementa loop de trabalho que respeita sem√¢ntica de quantum para
    escalonamento preemptivo. Combina sleep (I/O-bound) com c√°lculos
    (CPU-bound) para simular carga realista.
    
    Args:
        requisicao (dict): Metadados da tarefa contendo:
            - 'tempo_restante' (float): Tempo ainda n√£o processado.
            - 'tempo_exec' (float): Tempo total original (fallback).
        quantum (float): Limite de tempo para esta fatia de execu√ß√£o.
                        Se 0, executa at√© completar (modo FIFO/SJF).
                        
    Returns:
        tuple: (tempo_restante_novo, tempo_executado) onde:
            - tempo_restante_novo (float): Saldo ap√≥s esta execu√ß√£o.
            - tempo_executado (float): Dura√ß√£o efetiva desta fatia.
            
    Behavior:
        - Quantum 0: Executa tarefa completa (modo n√£o-preemptivo).
        - Quantum > 0: Limita execu√ß√£o a min(quantum, tempo_restante).
        - Trabalho sint√©tico: sleep + c√°lculos aritm√©ticos (simula mix I/O+CPU).
        
    Note:
        - Chunks de 0.1s balanceiam responsividade vs overhead de itera√ß√£o.
        - C√°lculo de quadrados gera carga CPU mensur√°vel para testes de desempenho.
    """
    # Obt√©m tempo pendente (prioriza 'tempo_restante' se dispon√≠vel)
    tempo_restante = requisicao.get("tempo_restante", requisicao.get("tempo_exec"))
    
    # Determina dura√ß√£o desta fatia de execu√ß√£o
    if quantum == 0:
        # Modo n√£o-preemptivo: executa at√© o fim
        tempo_execucao = tempo_restante
    else:
        # Modo preemptivo: respeita quantum ou termina se restar menos
        tempo_execucao = min(quantum, tempo_restante)

    # Marca in√≠cio para medi√ß√£o precisa de tempo decorrido
    start = time.time()
    elapsed = 0
    
    # Loop de trabalho: simula processamento em chunks
    while elapsed < tempo_execucao:
        # Calcula dura√ß√£o do pr√≥ximo chunk (m√°ximo 0.1s)
        chunk = min(0.1, tempo_execucao - elapsed)
        
        # Simula I/O-bound: espera passiva (libera CPU)
        time.sleep(chunk)
        
        # Simula CPU-bound: c√°lculo sint√©tico (consome ciclos)
        # Sum de quadrados gera carga mensur√°vel sem otimiza√ß√£o do interpretador
        _ = sum(i * i for i in range(1000))
        
        # Atualiza tempo decorrido (medi√ß√£o real, n√£o sleep nominal)
        elapsed = time.time() - start

    # Calcula saldo restante (garante n√£o-negativo por arredondamento)
    novo_tempo_restante = max(0, tempo_restante - tempo_execucao)
    return novo_tempo_restante, tempo_execucao

def process_task_thread(conn, lock, requisicao, quantum, server_id):
    """Worker thread que processa uma tarefa e envia resposta ao orquestrador.

    Cada tarefa recebida pelo servidor √© executada em uma thread independente,
    permitindo paralelismo real (m√∫ltiplas tarefas simult√¢neas por servidor).
    Ap√≥s processamento, envia resposta via socket com resultado (CONCLUSAO
    ou PREEMPCAO).
    
    Args:
        conn (socket.socket): Conex√£o TCP estabelecida com o orquestrador.
        lock (threading.Lock): Lock para serializar envios no socket compartilhado.
        requisicao (dict): Metadados da tarefa a processar.
        quantum (float): Limite de tempo por fatia (0 = sem limite).
        server_id (int): ID deste servidor (para logging/depura√ß√£o).
        
    Side Effects:
        - Modifica `requisicao['tempo_restante']` in-place.
        - Envia JSON via socket (CONCLUSAO ou PREEMPCAO).
        
    Thread Safety:
        - Lock protege send_json() contra intercala√ß√£o de mensagens.
        - `requisicao` √© c√≥pia independente (n√£o compartilhada entre threads).
        
    Protocol:
        Envia um dos dois tipos de resposta:
        - CONCLUSAO: Tarefa finalizada (tempo_restante ‚â§ 0.05s).
        - PREEMPCAO: Quantum esgotado, tarefa deve retornar √† fila.
    """
    # Extrai identificador para rastreabilidade
    req_id = requisicao.get("id")
    
    # Executa fatia de trabalho (respeita quantum)
    novo_restante, executado = fake_inference_core(requisicao, quantum)
    
    # Atualiza estado da requisi√ß√£o in-place (arredonda para evitar drift)
    requisicao['tempo_restante'] = round(novo_restante, 2)

    # Decide tipo de resposta baseado em crit√©rio de conclus√£o
    # Threshold de 0.05s tolera imprecis√µes de ponto flutuante
    if novo_restante <= 0.05:
        # Tarefa completa: envia resultado final
        resposta = {
            "tipo": "CONCLUSAO",
            "req_id": req_id,
            "servidor_id": server_id,
            "tempo_final": time.time(),       # Timestamp para m√©tricas
            "dados_originais": requisicao      # Estado final para auditoria
        }
    else:
        # Quantum esgotado: sinaliza preemp√ß√£o
        resposta = {
            "tipo": "PREEMPCAO",
            "req_id": req_id,
            "servidor_id": server_id,
            "tempo_restante": novo_restante,  # Saldo para pr√≥xima fatia
            "dados_originais": requisicao      # Estado parcial preservado
        }

    # Envia resposta com prote√ß√£o contra intercala√ß√£o
    # Lock necess√°rio pois m√∫ltiplas threads compartilham mesmo socket
    with lock:
        try:
            send_json(conn, resposta)
        except:
            # Falhas de envio (ex: conex√£o fechada) s√£o ignoradas
            # Servidor n√£o tem como reprocessar, responsabilidade do orquestrador
            pass

def run_socket_server(server_id, port, quantum):
    """Processo servidor independente que gerencia execu√ß√£o paralela de tarefas.

    Implementa servidor TCP multi-threaded que:
    1. Aceita conex√µes do orquestrador (permanentes durante sess√£o)
    2. Recebe tarefas via mensagens JSON delimitadas por '\n'
    3. Processa tarefas em threads paralelas (at√© capacidade do servidor)
    4. Envia respostas (CONCLUSAO/PREEMPCAO) de volta ao orquestrador
    5. Suporta shutdown gracioso via mensagem "STOP"
    
    Args:
        server_id (int): Identificador √∫nico deste servidor.
        port (int): Porta TCP para escutar (tipicamente 5000 + server_id).
        quantum (float): Limite de tempo por fatia de execu√ß√£o (0 = sem limite).
                        
    Lifecycle:
        1. Cria socket TCP em modo SO_REUSEADDR (permite restart r√°pido)
        2. Entra em loop accept() para aguardar conex√µes
        3. Para cada conex√£o: spawn thread por tarefa recebida
        4. Ao receber "STOP", encerra loops e fecha socket
        
    Concurrency:
        - Uma thread por tarefa ativa (paralelismo real limitado por GIL+I/O)
        - Lock por conex√£o protege envios no socket compartilhado
        - Threads s√£o daemon=True (encerram com processo pai)
        
    Protocol:
        - Input: JSON por linha (ex: {"id": 101, "tempo_exec": 5, ...})
        - Output: JSON por linha (ex: {"tipo": "CONCLUSAO", "req_id": 101, ...})
        - Control: String "STOP" encerra servidor
        
    Note:
        - Roda como processo separado (multiprocessing) para isolamento real.
        - SO_REUSEADDR evita erro "Address already in use" em restarts r√°pidos.
        - Backlog de 5 conex√µes pendentes suficiente para 1 cliente.
    """
    # Cria socket TCP IPv4
    server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    
    # Permite reusar porta imediatamente ap√≥s encerramento (evita TIME_WAIT)
    server_socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
    
    # Tenta ligar socket √† porta especificada
    try:
        server_socket.bind(('0.0.0.0', port))
        # Habilita modo listening com backlog=5 (at√© 5 conex√µes pendentes)
        server_socket.listen(5)
    except Exception as e:
        # Falha cr√≠tica: porta ocupada ou sem permiss√µes
        print(f"[Server {server_id}] Erro ao ligar na porta {port}: {e}")
        return

    # Loop principal: aguarda conex√µes indefinidamente
    while True:
        try:
            # Aceita pr√≥xima conex√£o (bloqueia at√© cliente conectar)
            conn, addr = server_socket.accept()
            
            # Lock exclusivo para esta conex√£o (protege send_json concorrente)
            socket_lock = threading.Lock()
            
            # Loop de recep√ß√£o: processa mensagens at√© STOP ou desconex√£o
            while True:
                # L√™ pr√≥xima mensagem JSON (bloqueia at√© receber linha completa)
                requisicao = recv_json(conn)
                
                # Verifica condi√ß√µes de t√©rmino
                if not requisicao:           # Conex√£o fechada ou erro de leitura
                    break
                if requisicao == "STOP":     # Comando de shutdown
                    break

                # Mensagem normal: trata como tarefa a processar
                # ARQUITETURA PARALELA: Uma thread por tarefa
                # Permite m√∫ltiplas tarefas simult√¢neas no mesmo servidor
                t = threading.Thread(
                    target=process_task_thread,
                    args=(conn, socket_lock, requisicao, quantum, server_id),
                    daemon=True  # Thread morre com processo pai
                )
                t.start()
            
            # Cleanup: fecha conex√£o ap√≥s loop interno
            conn.close()
            
            # Se recebeu STOP, encerra servidor completamente
            if requisicao == "STOP":
                break

        except Exception as e:
            # Erro de comunica√ß√£o: loga silenciosamente e aguarda pr√≥xima conex√£o
            # Comentado para evitar poluir stdout com erros esperados (ex: RST)
            # print(f"Erro na conex√£o do server {server_id}: {e}")
            pass
            
    # Cleanup final: fecha socket de escuta ao sair do loop
    server_socket.close()

# ============================================================================
# 6. ESCALONADOR (CLIENTE)
# ============================================================================

class TaskScheduler:
    """Orquestrador central de tarefas com pol√≠ticas de escalonamento distribu√≠do.

    Coordena execu√ß√£o de tarefas em cluster de servidores TCP independentes,
    implementando estrat√©gias cl√°ssicas de escalonamento de processos adaptadas
    para ambiente distribu√≠do. Gerencia ciclo completo: carregamento, distribui√ß√£o,
    monitoramento e coleta de resultados.
    
    Responsabilidades:
        - **Carregamento**: L√™ configura√ß√£o JSON com servidores e tarefas.
        - **Distribui√ß√£o**: Aloca tarefas usando Quick Fit (Least Connections).
        - **Escalonamento**: Aplica SJF, Round Robin, Prioridade ou FIFO.
        - **Comunica√ß√£o**: Mant√©m pontes full-duplex via sockets TCP.
        - **Monitoramento**: Rastreia carga ativa, tarefas conclu√≠das, m√©tricas.
        - **Relat√≥rio**: Calcula estat√≠sticas de utiliza√ß√£o e desempenho.
        
    Estrat√©gias Suportadas:
        - **SJF**: Shortest Job First (quantum=0, n√£o-preemptivo).
        - **ROUND_ROBIN**: Quantum fixo com preemp√ß√£o c√≠clica.
        - **PRIORIDADE**: Ordena por prioridade num√©rica (1=alta, 3=baixa).
        - **FIFO**: First In First Out, ordem de chegada.
        
    Arquitetura:
        - 1 processo orquestrador (este) + N processos servidores.
        - 1 thread de ponte (socket_bridge) por servidor.
        - 1 thread de monitoramento (metrics) compartilhada.
        - Comunica√ß√£o via JSON sobre TCP com protocolo de mensagens.
    """

    def __init__(self, json_path, strategy="ROUND_ROBIN", quantum=2):
        """Inicializa orquestrador com configura√ß√£o e estruturas de dados.
        
        Args:
            json_path (str|Path): Caminho para JSON com 'servidores' e 'requisicoes'.
            strategy (str): Estrat√©gia de escalonamento. Valores aceitos:
                           "SJF", "ROUND_ROBIN", "PRIORIDADE", "FIFO".
            quantum (float): Fatia de tempo para Round Robin (em segundos).
                            Ignorado para SJF (sempre 0).
                            
        Attributes:
            json_path (str): Caminho do arquivo de configura√ß√£o.
            strategy (str): Estrat√©gia normalizada (uppercase).
            quantum (float): Quantum efetivo (0 para SJF).
            logger (RealtimeLogger): Sistema de logging thread-safe.
            servidores (list[dict]): Configura√ß√£o dos servidores carregada.
            requisicoes (list[dict]): Lista de tarefas a processar.
            task_queues (dict): Mapa {server_id: Queue} com filas locais.
            lista_global_pendentes (list): Tarefas ainda n√£o alocadas.
            server_load (dict): Mapa {server_id: int} com contadores de carga.
            load_lock (Lock): Prote√ß√£o para server_load (modifica√ß√µes concorrentes).
            concluidas (set): IDs de tarefas j√° finalizadas.
            dados_concluidos (list): Metadados completos de tarefas conclu√≠das.
            total_reqs (int): N√∫mero total de tarefas (para calcular progresso).
            quick_fit (QuickFitAllocator): Alocador de carga Least Connections.
            running (bool): Flag de controle para loops de orquestra√ß√£o.
            
        Note:
            - Quantum √© for√ßado a 0 para SJF (sem√¢ntica n√£o-preemptiva).
            - task_queues criadas dinamicamente para N servidores.
            - lista_global_pendentes √© c√≥pia (modifica√ß√µes n√£o afetam original).
        """
        # Configura√ß√£o b√°sica
        self.json_path = json_path
        self.strategy = strategy.upper()  # Normaliza para compara√ß√µes
        
        # Quantum: 0 para SJF (n√£o-preemptivo), valor fornecido para outros
        self.quantum = quantum if strategy != "SJF" else 0
        
        # Sistema de logging thread-safe
        self.logger = RealtimeLogger()
        
        # Carrega servidores e requisi√ß√µes do JSON
        self._load_config()

        # Estruturas de distribui√ß√£o: uma fila por servidor
        # Filas s√£o thread-safe nativamente (queue.Queue)
        self.task_queues = {srv["id"]: queue.Queue() for srv in self.servidores}
        
        # Lista global: tarefas ainda n√£o alocadas a nenhum servidor
        # C√≥pia independente permite manipula√ß√£o destrutiva
        self.lista_global_pendentes = list(self.requisicoes)
        
        # RASTREAMENTO DE CARGA ATIVA
        # server_load: contador de tarefas em execu√ß√£o (n√£o apenas na fila)
        self.server_load = {srv["id"]: 0 for srv in self.servidores}
        # load_lock: protege server_load contra condi√ß√µes de corrida
        self.load_lock = threading.Lock()

        # Rastreamento de conclus√£o
        self.concluidas = set()           # IDs para lookup r√°pido (O(1))
        self.dados_concluidos = []        # Dados completos para relat√≥rio
        self.total_reqs = len(self.requisicoes)  # Total para calcular progresso
        
        # Alocador de servidores (Least Connections)
        self.quick_fit = QuickFitAllocator(self.servidores)
        
        # Flag de controle do loop de orquestra√ß√£o
        self.running = True

    def _load_config(self):
        """Carrega e pr√©-processa configura√ß√£o do arquivo JSON.
        
        L√™ estrutura JSON esperada com chaves 'servidores' e 'requisicoes',
        validando implicitamente formato e inicializando campos derivados.
        
        Side Effects:
            - Define self.servidores: Lista de dicts com {id, capacidade, ...}.
            - Define self.requisicoes: Lista de dicts com {id, tipo, tempo_exec, ...}.
            - Adiciona campo 'tempo_restante' a cada requisi√ß√£o (inicialmente = tempo_exec).
            
        Raises:
            FileNotFoundError: Se json_path n√£o existir.
            json.JSONDecodeError: Se arquivo n√£o for JSON v√°lido.
            KeyError: Se estrutura JSON faltar chaves 'servidores' ou 'requisicoes'.
            
        Note:
            - 'tempo_restante' permite rastrear progress√£o de tarefas preemptivas.
            - Modifica√ß√£o in-place das requisi√ß√µes √© segura (lista ser√° copiada).
        """
        with open(self.json_path, "r", encoding="utf-8") as f:
            # Parse JSON completo
            d = json.load(f)
            
            # Extrai se√ß√µes de configura√ß√£o (lan√ßa KeyError se ausentes)
            self.servidores = d["servidores"]
            self.requisicoes = d["requisicoes"]
            
            # Pr√©-processamento: inicializa tempo restante
            # Cada requisi√ß√£o come√ßa com tempo_restante = tempo_exec
            for r in self.requisicoes:
                r['tempo_restante'] = r['tempo_exec']

    def _priority_name(self, p):
        """Converte n√≠vel num√©rico de prioridade em label humanizado.
        
        Args:
            p (int): Prioridade num√©rica (1, 2 ou 3).
            
        Returns:
            str: "Alta" (p=1), "M√©dia" (p=2) ou "Baixa" (outros).
            
        Note:
            - Usado apenas para logging/UI, n√£o afeta l√≥gica de escalonamento.
            - Padr√£o "Baixa" para valores inesperados (defensive programming).
        """
        return "Alta" if p == 1 else "M√©dia" if p == 2 else "Baixa"

    # --- PONTE FULL-DUPLEX ---
    def socket_bridge(self, server_id, port):
        """Estabelece canal de comunica√ß√£o bidirecional com servidor via TCP.

        Implementa padr√£o full-duplex: thread separada para envio (sender) +
        loop principal para recep√ß√£o (receiver). Gerencia contabilidade de
        carga ativa e sincroniza√ß√£o de estado entre orquestrador e servidor.
        
        Args:
            server_id (int): Identificador do servidor alvo.
            port (int): Porta TCP onde servidor est√° escutando.
            
        Lifecycle:
            1. Tenta conectar ao servidor (at√© 10 tentativas com retry).
            2. Spawna thread sender para enviar tarefas da fila.
            3. Loop principal receiver processa respostas (CONCLUSAO/PREEMPCAO).
            4. Ao encerrar, envia comando STOP e fecha socket.
            
        Concurrency:
            - Sender: Thread dedicada l√™ task_queues[server_id] e envia JSONs.
            - Receiver: Loop principal (esta thread) l√™ respostas e atualiza estado.
            - load_lock: Protege server_load contra condi√ß√µes de corrida.
            
        State Management:
            - Incrementa server_load ANTES de enviar tarefa (antecipa carga).
            - Decrementa server_load AO RECEBER resposta (libera slot).
            - CONCLUSAO: Move tarefa para concluidas, registra metrics.
            - PREEMPCAO: Retorna tarefa para lista_global_pendentes com tempo atualizado.
            
        Error Handling:
            - Retry com backoff exponencial (10 tentativas x 0.5s).
            - Falha de conex√£o: loga erro e retorna (servidor indispon√≠vel).
            - Erros de comunica√ß√£o: encerra ponte graciosamente.
            
        Note:
            - Roda em thread separada (uma por servidor).
            - Conex√£o permanente durante toda a sess√£o (n√£o reconecta).
        """
        # Cria socket TCP cliente
        client_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        
        # Retry loop: aguarda servidor inicializar (pode demorar alguns ms)
        connected = False
        for tentativa in range(10):
            try:
                client_socket.connect(('localhost', port))
                connected = True
                break
            except:
                # Servidor ainda n√£o pronto, aguarda antes de retry
                time.sleep(0.5)
        
        # Se todas as tentativas falharam, aborta ponte
        if not connected:
            print(f"‚ùå Falha ao conectar com Servidor {server_id} na porta {port}")
            return

        # ====================================================================
        # SENDER THREAD: Envia tarefas da fila para o servidor
        # ====================================================================
        def sender_loop():
            """Thread emissora: drena fila do servidor e envia tarefas via socket.
            
            Responsabilidades:
                - Bloqueia aguardando tarefas na task_queues[server_id].
                - Envia JSON via socket para servidor processar.
                - Incrementa server_load ANTES de enviar (reserva slot).
                - Trata comando especial "STOP" para encerramento gracioso.
                
            Termination:
                - self.running=False: Encerra ap√≥s timeout.
                - Comando "STOP": Envia para servidor e encerra.
                - Erro de socket: Encerra silenciosamente.
            """
            while self.running:
                try:
                    # Aguarda pr√≥xima tarefa com timeout (permite checagem de self.running)
                    task = self.task_queues[server_id].get(timeout=0.5)
                    
                    # Comando especial de encerramento
                    if task == "STOP":
                        try:
                            send_json(client_socket, "STOP")
                        except:
                            pass  # Servidor j√° pode ter fechado
                        break
                    
                    # CONTABILIDADE DE CARGA: Incrementa ANTES de enviar
                    # Garante que Quick Fit veja carga atualizada imediatamente
                    with self.load_lock:
                        self.server_load[server_id] += 1
                    
                    # Envia tarefa via socket (JSON serializado + '\n')
                    send_json(client_socket, task)
                    
                except queue.Empty:
                    # Timeout normal: verifica self.running e continua
                    continue
                except:
                    # Erro cr√≠tico (ex: socket fechado): encerra thread
                    break

        # Spawna thread sender (daemon=False para aguardar no join)
        t_sender = threading.Thread(target=sender_loop, daemon=False)
        t_sender.start()

        # ====================================================================
        # RECEIVER LOOP: Processa respostas do servidor (loop principal)
        # ====================================================================
        while self.running:
            try:
                # L√™ pr√≥xima resposta do servidor (bloqueia at√© receber)
                resposta = recv_json(client_socket)
                
                # Conex√£o fechada ou erro de leitura: encerra ponte
                if not resposta:
                    break

                # CONTABILIDADE DE CARGA: Decrementa AO RECEBER resposta
                # Libera slot para pr√≥xima tarefa (servidor ficou dispon√≠vel)
                with self.load_lock:
                    self.server_load[server_id] -= 1

                # ============================================================
                # Tipo: CONCLUSAO - Tarefa finalizada com sucesso
                # ============================================================
                if resposta['tipo'] == 'CONCLUSAO':
                    # Loga evento de conclus√£o
                    self.logger.log("CONCLUSAO", 
                                   req_id=resposta['req_id'], 
                                   servidor_id=server_id)
                    
                    # Atualiza estruturas de controle de forma at√¥mica
                    with self.logger.lock:
                        self.concluidas.add(resposta['req_id'])          # Marca como conclu√≠da
                        self.dados_concluidos.append(resposta)           # Armazena metadados
                        self.logger.metrics["requisicoes_completas"] += 1  # Incrementa m√©trica
                
                # ============================================================
                # Tipo: PREEMPCAO - Quantum esgotado, tarefa retorna √† fila
                # ============================================================
                elif resposta['tipo'] == 'PREEMPCAO':
                    # Loga evento de preemp√ß√£o com tempo restante
                    self.logger.log("PREEMPCAO", 
                                   req_id=resposta['req_id'], 
                                   servidor_id=server_id, 
                                   detalhes=resposta['tempo_restante'])
                    
                    # Incrementa contador de preemp√ß√µes
                    self.logger.add_metric("preempcoes", 1)
                    
                    # Recupera estado atualizado da tarefa (com tempo_restante reduzido)
                    req_atualizada = resposta['dados_originais']
                    req_atualizada['tempo_restante'] = resposta['tempo_restante']
                    
                    # Retorna tarefa para fila global (ser√° reescalonada)
                    self.lista_global_pendentes.append(req_atualizada)

            except:
                # Erro de comunica√ß√£o: encerra ponte
                break
        
        # Cleanup: aguarda thread sender terminar e fecha socket
        t_sender.join()
        client_socket.close()

    # --- ORQUESTRADOR ---
    def orchestrator_loop(self):
        """Loop central de escalonamento e distribui√ß√£o de tarefas.

        Implementa ciclo cont√≠nuo de:
        1. Ordena√ß√£o: Aplica estrat√©gia de escalonamento √† fila global.
        2. Sele√ß√£o: Consulta Quick Fit para escolher servidor ideal.
        3. Aloca√ß√£o: Enfileira tarefa na fila do servidor escolhido.
        4. Verifica√ß√£o: Checa condi√ß√µes de t√©rmino.
        
        Estrat√©gias de Ordena√ß√£o:
            - PRIORIDADE: Sort por (prioridade, id) crescente.
            - SJF: Sort por tempo_exec crescente (shortest first).
            - ROUND_ROBIN/FIFO: Ordem de inser√ß√£o preservada (FIFO impl√≠cito).
            
        Termination Conditions:
            - Lista global vazia E todas as tarefas conclu√≠das E carga zerada.
            - self.running=False (sinalizado externamente).
            
        Concurrency:
            - load_lock: Protege leitura de server_load (snapshot consistente).
            - task_queues s√£o thread-safe nativamente (queue.Queue).
            
        Note:
            - Polling com sleep(0.01) para balancear responsividade vs CPU.
            - Rollback autom√°tico (insert(0)) se aloca√ß√£o falhar.
        """
        # Loga in√≠cio da orquestra√ß√£o
        self.logger.log("INFO", detalhes=f"Orquestrador (TCP) iniciado. Estrat√©gia: {self.strategy}")
        
        # Loop principal: executa at√© self.running=False
        while self.running:
            # ================================================================
            # VERIFICA√á√ÉO DE T√âRMINO
            # ================================================================
            # Condi√ß√£o 1: Lista global vazia (nada mais a escalonar)
            # Condi√ß√£o 2: Todas as tarefas marcadas como conclu√≠das
            if not self.lista_global_pendentes and len(self.concluidas) == self.total_reqs:
                # Condi√ß√£o 3: Carga ativa zerada (ningu√©m trabalhando)
                with self.load_lock:
                    active = sum(self.server_load.values())
                if active == 0:
                    # Todas as condi√ß√µes satisfeitas: sistema ocioso
                    time.sleep(0.5)
                    continue

            # Se lista global vazia mas ainda h√° tarefas em execu√ß√£o, aguarda
            if not self.lista_global_pendentes:
                time.sleep(0.1)
                continue

            # ================================================================
            # FASE 1: ORDENA√á√ÉO (Aplicar estrat√©gia de escalonamento)
            # ================================================================
            if self.strategy == "PRIORIDADE":
                # Ordena por prioridade (1=alta, 3=baixa), desempate por ID
                self.lista_global_pendentes.sort(key=lambda x: (x['prioridade'], x['id']))
            elif self.strategy == "SJF":
                # Shortest Job First: ordena por tempo de execu√ß√£o
                self.lista_global_pendentes.sort(key=lambda x: x['tempo_exec'])
            # ROUND_ROBIN/FIFO: n√£o reordena (mant√©m ordem FIFO natural)
            
            
            # ================================================================
            # FASE 2: ALOCA√á√ÉO (Quick Fit + Distribui√ß√£o)
            # ================================================================
            # Obt√©m snapshot thread-safe da carga atual
            with self.load_lock:
                current_load = self.server_load.copy()
            
            # Calcula estado atualizado de todos os servidores
            estado = self.quick_fit.calcular_estado_servidores(self.task_queues, current_load)
            
            # Candidata: primeira tarefa ap√≥s ordena√ß√£o (maior prioridade)
            req_candidata = self.lista_global_pendentes[0]
            
            # Aplica heur√≠stica Least Connections para escolher servidor
            melhor_srv = self.quick_fit.encontrar_melhor_servidor(req_candidata, estado)

            # ============================================================
            # Caso 1: Servidor dispon√≠vel encontrado
            # ============================================================
            if melhor_srv is not None:
                # Remove tarefa da lista global (commit da aloca√ß√£o)
                req_a_enviar = self.lista_global_pendentes.pop(0)
                
                try:
                    # Enfileira tarefa na fila do servidor escolhido
                    # Thread sender da ponte consumir√° e enviar√° via socket
                    self.task_queues[melhor_srv].put(req_a_enviar)
                    
                    # Prepara informa√ß√µes para logging
                    prio_lbl = self._priority_name(req_a_enviar.get('prioridade', 0))
                    load_real = current_load.get(melhor_srv, 0)
                    cap_real = estado[melhor_srv]['capacidade']
                    
                    # Loga evento de atribui√ß√£o com m√©tricas de carga
                    self.logger.log(
                        "ATRIBUICAO",
                        req_id=req_a_enviar['id'],
                        servidor_id=melhor_srv,
                        prioridade=prio_lbl,
                        detalhes=f"Carga: {load_real}/{cap_real}"
                    )
                    
                except:
                    # Falha ao enfileirar: rollback (retorna tarefa ao in√≠cio)
                    # Condi√ß√£o rara (fila n√£o deve falhar), mas garante consist√™ncia
                    self.lista_global_pendentes.insert(0, req_a_enviar)
            
            # ============================================================
            # Caso 2: Nenhum servidor dispon√≠vel (todos saturados)
            # ============================================================
            else:
                # Aguarda antes de tentar novamente (backpressure)
                time.sleep(0.1)
            
            # Pequeno delay para evitar busy-waiting (economiza CPU)
            time.sleep(0.01)

    def monitor_loop(self):
        """Thread de monitoramento cont√≠nuo de recursos do sistema.
        
        Coleta m√©tricas de CPU em intervalos regulares para an√°lise de
        desempenho. Roda como daemon thread (encerra com processo principal).
        
        Behavior:
            - Amostra CPU a cada 1 segundo (psutil.cpu_percent).
            - Armazena valores em logger.metrics["cpu_valores"] (lista).
            - Loop termina quando self.running=False.
            
        Note:
            - interval=1 no cpu_percent causa sleep de 1s entre amostras.
            - M√©tricas agregadas (m√©dia, pico) calculadas em exibir_relatorio.
        """
        while self.running:
            # Obt√©m percentual de uso de CPU (m√©dia de 1s)
            cpu = psutil.cpu_percent(interval=1)
            # Adiciona √† lista de valores (thread-safe via lock interno)
            self.logger.add_metric("cpu_valores", cpu)

    def exibir_relatorio(self, tempo_total):
        """Gera e imprime relat√≥rio estat√≠stico de desempenho do sistema.
        
        Calcula m√©tricas agregadas sobre execu√ß√£o completa e apresenta
        resumo formatado com estat√≠sticas principais.
        
        Args:
            tempo_total (float): Dura√ß√£o total da execu√ß√£o em segundos.
            
        M√©tricas Calculadas:
            - Tarefas conclu√≠das vs total.
            - Tempo total de execu√ß√£o.
            - Tempo m√©dio de resposta (from submit to complete).
            - Total de preemp√ß√µes (Round Robin).
            - Throughput (tarefas/segundo).
            
        Note:
            - Filtra dados_concluidos para garantir apenas dicts v√°lidos.
            - Tempo de resposta: delta entre tempo_final e start_time.
            - Tratamento especial para caso de nenhuma tarefa conclu√≠da.
        """
        # Cabe√ßalho do relat√≥rio
        print("\n" + "="*55)
        print("üìä RESUMO FINAL (MODO SOCKETS TCP/IP)")
        print("="*55)
        
        # Sanitiza√ß√£o: filtra apenas dicts v√°lidos (ignora poss√≠veis None/erros)
        dados_validos = [r for r in self.dados_concluidos if isinstance(r, dict)]
        total = len(dados_validos)
        
        # Caso especial: nenhuma tarefa foi conclu√≠da
        if total == 0:
            print("Nenhuma tarefa conclu√≠da.")
            return

        # Calcula tempos de resposta individuais
        tempos_resp = []
        for r in dados_validos:
            # Tempo de resposta = timestamp de conclus√£o - in√≠cio do sistema
            t_final = r.get('tempo_final', time.time())
            tempos_resp.append(t_final - self.logger.start_time)

        # M√©tricas agregadas
        media_resp = sum(tempos_resp)/total if total > 0 else 0
        preempcoes = self.logger.metrics["preempcoes"]
        
        # Impress√£o formatada
        print(f"‚úÖ Requisi√ß√µes: {total}/{self.total_reqs}")
        print(f"‚è±Ô∏è  Tempo Total: {tempo_total:.2f}s")
        print(f"üìà Tempo M√©dio de Resposta: {media_resp:.2f}s")
        print(f"‚è∏Ô∏è  Total de Preemp√ß√µes: {preempcoes}")
        if tempo_total > 0:
            # Throughput: tarefas conclu√≠das por segundo
            print(f"üöÄ Throughput: {total/tempo_total:.2f} req/s")
        print("\n" + "="*55 + "\n")

    def run(self):
        """Orquestra ciclo de vida completo do sistema distribu√≠do.
        
        Sequencia de inicializa√ß√£o:
        1. Spawna processos servidores TCP independentes.
        2. Aguarda inicializa√ß√£o (bind/listen de sockets).
        3. Cria threads de ponte (uma por servidor).
        4. Inicia threads de orquestra√ß√£o e monitoramento.
        5. Aguarda conclus√£o de todas as tarefas.
        6. Shutdown gracioso: sinaliza threads, aguarda joins, termina processos.
        7. Exibe relat√≥rio final de desempenho.
        
        Arquitetura de Concorr√™ncia:
            - N processos: Servidores TCP (multiprocessing).
            - N threads: Pontes full-duplex (uma por servidor).
            - 1 thread: Orquestrador (escalonamento + aloca√ß√£o).
            - 1 thread: Monitor de recursos (daemon).
            - Main thread: Aguarda conclus√£o e coordena shutdown.
            
        Shutdown Gracioso:
            - Seta self.running=False (threads checam periodicamente).
            - Envia "STOP" para todas as filas (threads sender encerram).
            - Join em bridge_threads e t_orq (aguarda conclus√£o limpa).
            - Terminate em server_processes (for√ßa encerramento).
            
        Error Recovery:
            - KeyboardInterrupt: Captura Ctrl+C e encerra graciosamente.
            - Verifica√ß√£o de health: Alerta se todos os servidores ca√≠rem.
            
        Note:
            - Sleep inicial de 2s garante servidores prontos antes de conex√µes.
            - Daemon thread (monitor) encerra automaticamente com main.
        """
        # Banner de inicializa√ß√£o
        print(f"\nüöÄ INICIANDO SISTEMA DISTRIBU√çDO: {self.strategy}")
        
        # ====================================================================
        # FASE 1: SPAWNAR PROCESSOS SERVIDORES
        # ====================================================================
        server_processes = []
        for srv in self.servidores:
            sid = srv['id']
            # Calcula porta dinamicamente (5000 + ID)
            port = get_port_for_server(sid)
            
            # Cria processo servidor independente
            p = multiprocessing.Process(
                target=run_socket_server,
                args=(sid, port, self.quantum),
                daemon=False  # Permite join expl√≠cito
            )
            p.start()
            server_processes.append(p)
        
        # Aguarda servidores iniciarem (bind + listen)
        print("‚è≥ Aguardando servidores iniciarem...")
        time.sleep(2)

        # Marca in√≠cio da contagem de tempo
        self.logger.start_time = time.time()
        self.logger.log("INICIO")

        # ====================================================================
        # FASE 2: CRIAR THREADS DE PONTE (Full-Duplex)
        # ====================================================================
        bridge_threads = []
        for srv in self.servidores:
            sid = srv['id']
            port = get_port_for_server(sid)
            
            # Cria thread de ponte bidirecional (sender + receiver)
            t = threading.Thread(
                target=self.socket_bridge,
                args=(sid, port),
                daemon=False  # Aguardamos join expl√≠cito
            )
            t.start()
            bridge_threads.append(t)

        # ====================================================================
        # FASE 3: INICIAR ORQUESTRADOR E MONITOR
        # ====================================================================
        # Thread de orquestra√ß√£o (escalonamento + distribui√ß√£o)
        t_orq = threading.Thread(target=self.orchestrator_loop, daemon=False)
        t_orq.start()
        
        # Thread de monitoramento (m√©tricas de CPU) - daemon encerra com main
        t_mon = threading.Thread(target=self.monitor_loop, daemon=True)
        t_mon.start()

        # ====================================================================
        # FASE 4: AGUARDAR CONCLUS√ÉO DE TODAS AS TAREFAS
        # ====================================================================
        try:
            # Loop de espera: verifica conclus√£o a cada 0.5s
            while len(self.concluidas) < self.total_reqs:
                time.sleep(0.5)
                
                # Health check: verifica se servidores ainda est√£o ativos
                if not any(p.is_alive() for p in server_processes):
                    print("‚ö†Ô∏è  CR√çTICO: Todos os servidores ca√≠ram!")
                    break
                    
        except KeyboardInterrupt:
            # Usu√°rio interrompeu com Ctrl+C
            print("\nInterrup√ß√£o do usu√°rio. Encerrando graciosamente...")

        # ====================================================================
        # FASE 5: SHUTDOWN GRACIOSO
        # ====================================================================
        # Sinaliza threads para encerrar
        self.running = False
        
        # Calcula tempo total de execu√ß√£o
        tempo_total = time.time() - self.logger.start_time

        # Envia comando STOP para todas as filas (threads sender consumir√£o)
        for q in self.task_queues.values():
            q.put("STOP")
        
        # Aguarda threads de ponte encerrarem (enviam STOP aos servidores)
        for t in bridge_threads:
            t.join(timeout=5)  # Timeout 5s para evitar deadlock
        
        # Aguarda thread de orquestra√ß√£o encerrar
        t_orq.join(timeout=5)
        
        # For√ßa encerramento de processos servidores (SIGTERM)
        for p in server_processes:
            p.terminate()
            p.join(timeout=2)  # Aguarda at√© 2s por processo

        # ====================================================================
        # FASE 6: RELAT√ìRIO FINAL
        # ====================================================================
        self.logger.log("FIM")
        self.exibir_relatorio(tempo_total)

# ============================================================================
# MAIN
# ============================================================================

def main():
    """Entry point principal: Interface CLI para sele√ß√£o de estrat√©gia.
    
    Apresenta menu interativo permitindo escolha entre 4 estrat√©gias de
    escalonamento. Instancia TaskScheduler com configura√ß√£o escolhida e
    inicia execu√ß√£o do sistema distribu√≠do.
    
    Op√ß√µes de Estrat√©gia:
        1. SJF (Shortest Job First):
           - Ordena por tempo_exec crescente.
           - Quantum=0 (n√£o-preemptivo, executa at√© o fim).
           - Minimiza tempo m√©dio de resposta para workloads heterog√™neos.
           
        2. ROUND_ROBIN:
           - Ordem FIFO com quantum=2s.
           - Preemptivo: tarefas rotacionam a cada 2s.
           - Garante fairness, evita starva√ß√£o.
           
        3. PRIORIDADE:
           - Ordena por prioridade (1=alta, 3=baixa) + ID.
           - Quantum=2s (preemptivo dentro de mesma prioridade).
           - Favorece tarefas cr√≠ticas.
           
        4. FIFO (Round Robin sem Quantum):
           - Ordem de chegada (First In First Out).
           - Quantum=0 (n√£o-preemptivo).
           - Simplicidade m√°xima, sem overhead de preemp√ß√£o.
           
    Behavior:
        - Input inv√°lido: Defaults para ROUND_ROBIN (quantum=2).
        - Leitura de tasks.json via constante TASKS_PATH.
        - Execu√ß√£o bloqueante: aguarda conclus√£o de todas as tarefas.
        
    Note:
        - multiprocessing.freeze_support() necess√°rio para Windows (PyInstaller).
        - Execu√ß√£o interativa, n√£o retorna at√© conclus√£o ou Ctrl+C.
    """
    # Apresenta menu de op√ß√µes
    print("\n" + "="*50)
    print("  SISTEMA DE ORQUESTRA√á√ÉO DISTRIBU√çDA VIA SOCKETS")
    print("="*50)
    print("Escolha a estrat√©gia de escalonamento:")
    print()
    print("1. SJF (Shortest Job First) - N√£o-preemptivo")
    print("2. ROUND_ROBIN - Quantum = 2s")
    print("3. PRIORIDADE - Com quantum 2s")
    print("4. FIFO - Ordem de chegada, n√£o-preemptivo")
    print("="*50)
    
    # L√™ escolha do usu√°rio
    opt = input("Escolha (1-4): ").strip()
    
    # Mapa de configura√ß√µes: op√ß√£o -> (estrat√©gia, quantum)
    cfg = {
        "1": ("SJF", 0),              # SJF: quantum 0 (n√£o-preemptivo)
        "2": ("ROUND_ROBIN", 2),      # RR: quantum 2s
        "3": ("PRIORIDADE", 2),       # Prioridade: quantum 2s
        "4": ("ROUND_ROBIN", 0)       # FIFO: RR com quantum 0 (equivalente)
    }
    
    # Extrai configura√ß√£o (default: RR com quantum 2s)
    strat, quant = cfg.get(opt, ("ROUND_ROBIN", 2))

    # Instancia orquestrador com configura√ß√£o escolhida
    app = TaskScheduler(TASKS_PATH, strategy=strat, quantum=quant)
    
    # Inicia execu√ß√£o (bloqueia at√© conclus√£o)
    app.run()

if __name__ == "__main__":
    # Suporte para Windows (freeze para exe standalone via PyInstaller)
    multiprocessing.freeze_support()
    
    # Executa interface CLI
    main()